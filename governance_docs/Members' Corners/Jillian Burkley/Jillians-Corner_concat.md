## Continuation Executive Summary

**Ethical considerations:** According to CIDDL (2024), ensuring equitable access to AI technologies is crucial to prevent exacerbating existing educational inequalities, as students in well-funded schools may have greater access to cutting-edge AI tools.

These challenges are particularly acute for the 7.5 million students receiving special education services nationwide (National Center for Education Statistics [NCES] (2024). Without structured intervention, the increasing adoption of AI tools risks exacerbating educational disparities rather than reducing them (Holmes et al., 2022).

## Program Framework and Theoretical Foundation

The AIEIP is grounded in the Diversity, Equity, Intersectionality, Power, and Anti-Racism (DEIPAR) framework (Dyer & Gushwa, 2023), ensuring that social justice and inclusion remain central to all implementation efforts. Two additional theoretical perspectives complement this foundation:

**Diffusion of Innovations Theory** (Dearing & Cox, 2018): Guides the phased implementation approach and adoption strategies for educators with varying levels of technology comfort.

**Constructivist Learning Theory** (Fernando & Marikar, 2017): Informs the development of training materials that engage educators in active, experiential learning about AI ethics.

Together, these frameworks create a comprehensive approach that addresses both the technical and social dimensions of ethical AI implementation in SPED settings. The AIEIP addresses a critical gap in educational technology governance by establishing a comprehensive framework for ethical AI implementation in special education. This initiative is particularly timely as AI adoption in K-12 education accelerates without corresponding ethical guidelines. The program's significance extends beyond compliance to address fundamental questions of equity, accessibility, and student rights.

## Continuation Executive Summary

## Program Components and Implementation Strategy

The AIEIP provides a multi-faceted approach to ethical AI integration through four interconnected components:

**Ethical AI Professional Development:** Tiered training modules for SPED educators on AI literacy, bias recognition, and ethical decision-making (Holmes et al., 2022; McMahon & Firestone, 2024). These modules are designed to accommodate varying levels of technological familiarity and incorporate trauma-informed approaches (Elliott et al., 2005).

**AI Compliance Frameworks:** Structured protocols and assessment tools that align AI-driven educational decisions with IDEA, FERPA, and Section 504 requirements (Roschelle et al., 2024; Holler & Zirkel, 2008). These frameworks ensure that AI tools support rather than undermine legal protections for students with disabilities. These frameworks translate complex regulations into actionable guidelines, allowing educators to evaluate AI tools against clearly defined compliance standards varying in technological proficiency. They can also be integrated into SAU41's existing professional development structure (SAU41, 2022).

**AI Bias Audits and Monitoring:** Regular assessment processes to identify and mitigate potential biases in AI-driven recommendations, particularly for students with intersecting marginalized identities (Nguyen et al., 2023). These audits will evaluate algorithmic fairness in student assessment, behavior monitoring, and personalized learning recommendations (Maslej et al., 2023; Akgun & Greenhow, 2021).

# PROBLEM STATEMENT

The increasing use of AI in SPED presents significant ethical, legal, and educational challenges. Despite the growing adoption of AI tools in K-12 education, no standardized federal or state regulations specifically address the ethical risks and compliance concerns associated with AI implementation in SPED (DOE, 2023; Roschelle et al., 2024). This regulatory gap affects approximately 7.5 million students nationwide who rely on special education services, with 31% of schools reporting critical shortages in SPED specialists, school psychologists, and case managers (National Center for Education Statistics, 2024).

>   About 7.5 million U.S. students depend on SPED services, but 31% of schools report a shortage of SPED specialists (NECES, 2024).

## Current Regulatory and Ethical Gaps

Current AI-driven educational tools are being rapidly deployed without adequate ethical oversight or legal frameworks. While federal laws such as IDEA, Section 504, and FERPA offer essential protections for students with disabilities, they were not designed to address the unique challenges posed by algorithmic decision-making (Haque & Li, 2024).

The White House's AI Bill of Rights (2023) emphasizes the importance of bias mitigation and transparency but lacks specific enforcement mechanisms within educational contexts. This regulatory vacuum has created significant vulnerabilities for SPED programs:

**Algorithmic bias in assessment and intervention:** Research by Nguyen et al. (2023) demonstrates that AI systems misclassify students with disabilities from marginalized backgrounds at rates up to 32% higher than their peers, potentially reinforcing existing inequities in identification and service delivery.

9

## Continuation of the Problem Statement

These alarming findings highlight the urgent need for structured ethical frameworks to guide AI implementation in special education settings.

**Data privacy vulnerabilities:** SPED students' sensitive diagnostic

information, behavioral data, and learning accommodations are increasingly processed through AI systems that lack adequate safeguards against privacy breaches (Roschelle et al., 2024).

**Lack of professional preparation**: The CIDDL (2024) highlights that few educators and educational leaders understand AI sufficiently to effectively advance education and special education. Faculty members responsible for preparing future special educators often lack access to comprehensive AI-focused training programs, which inhibits their ability to effectively integrate AI tools and content into teacher preparation (CIDDL,2024). Holmes et al. (2022) highlight significant concerns regarding data privacy and compliance in AI educational systems, noting that 'no framework has been workedout, no guidelines have been agreed, no policies have been developed, and no regulations have been enacted to address the specific ethical issues raised by the use of AI in education' (p. 505).

**Local Impact in SAU41**

These challenges are particularly acute within SAU41. The district has experienced persistent SPED staffing shortages since 2022, with critical positions such as school psychologists remaining vacant for multiple school years (SAU41, 2024-b). This staffing crisis has led to delays in SPED service implementation and increased reliance on AI-powered interventions to support overburdened staff. However, SAU41's Professional Growth Master Plan (2022-2027) does not include AI ethics training components, highlighting a critical professional development gap for educators and administrators (SAU41, 2022).

**Continuation of the Problem Statement**

**Intersection with Social Justice Concerns**

The lack of ethical frameworks for AI in SPED creates particularly significant risks for students with intersecting marginalized identities. Without appropriate oversight, AI systems can:

**Reinforce** historical biases in special education identification that have led to overrepresentation of students of color in certain disability categories (Baydar, 2022; Holmes et al., 2022)

**Exacerbate** existing disparities in disciplinary actions, with AI-driven behavior monitoring systems flagging behavioral differences in culturally diverse students as problematic (Maslej et al., 2023) **Implement** standardized approaches that fail to account for cultural, linguistic, and socioeconomic factors affecting student performance (Nguyen et al., 2023; Holmes et al., 2022)

**Compromise** student data privacy and autonomy, particularly for vulnerable populations already subject to heightened surveillance (Gamal, 2023)

Without a structured framework for ethical AI use, there is a risk that these technologies could reinforce existing disparities, misclassify students, delay critical interventions, and undermine the educational rights of students with disabilities (Maslej et al., 2023). Holmes et al. (2022) emphasize that "instructional strategies that aim to benefit all learners might disproportionately benefit more advantaged groups of learners" (p. 515), highlighting the need for "fairness-promoting algorithms" (p. 515) in educational AI systems. As AI becomes increasingly embedded in educational decision-making processes, ethical guidelines, comprehensive training, and robust oversight mechanisms become increasingly urgent, particularly for vulnerable student populations whose educational outcomes depend on equitable and appropriate technological implementation. The ethical implementation of AI in special education is fundamentally a social justice issue.

**Continuation of the Problem Statement**

Students with disabilities already encounter significant obstacles to achieving equitable education, and the introduction of AI without appropriate ethical guidelines may worsen these disparities. Holmes et al. (2022) express this concern, emphasizing that a major ethical issue is to guarantee that AI systems "do not show bias against a particular group" (p. 514) and stressing that these technologies pose a risk of "diminishing the quality of education for 'certain groups of students'" (p. 514).

For students with disabilities who also belong to marginalized racial, cultural, or socioeconomic backgrounds, these risks become even more pronounced. Holmes et al. (2022) recognize this intersectionality challenge, stating that "classifying students in terms of educational tests must account for the inherent ambiguity and variability in the measure" (p. 515). Haque and Li (2024) support this concern, noting that AI systems like ChatGPT learn from datasets that "may contain inherent biases and stereotypes" and that "certain social groups are underrepresented in the training data" (p. 8), potentially leading to unequal outcomes.

The AIEIP program addresses these ethical challenges with a thorough framework that aligns with the NASW Code of Ethics (2021), advocating for the responsible use of technology to promote human well-being. By implementing Holmes et al.'s (2022) plea for a "well-designed framework for engaging with ethics of AIED" (p. 504) and incorporating Haque and Li's (2024) suggestions for "improved transparency," "bias detection," and "ethical guidelines" (pp. 11-12), AIEIP aims to ensure that AI functions as a tool for educational equity rather than perpetuating existing power imbalances that disadvantage students with intersecting marginalized identities.

**Continuation of Mission and Vision**

**Core Values:**

Four fundamental values guide the AIEIP:

**Equity:** Ensuring AI tools promote fair and just outcomes for all students, particularly those with disabilities and from marginalized backgrounds

**Transparency:** Maintaining openness about how AI systems operate, make decisions, and use student data

**Accountability:** Establishing clear responsibilities and oversight mechanisms for AI implementation

**Innovation**: Embracing technological advancement while prioritizing student well-being and educational quality

AIEIP will integrate these ethical AI practices into SAU41's SPED services and lay the groundwork for an organizational structure that effectively supports this mission and vision.

**PROGRAM SERVICES**

The AIEIP ensures that AI is ethically integrated into SPED within SAU41. The program offers comprehensive services to address the key ethical, legal, and educational challenges associated with AI implementation in SPED, ensuring that AI tools used within the district promote equity, compliance, and fairness for all students.

**The following services will be provided through AIEIP:**

**Ethical AI Training Modules:** These professional development modules educate SPED educators and administrators on AI literacy, bias mitigation, and legal compliance. The training will emphasize the identification of algorithmic biases and the implementation of data privacy practices by FERPA, IDEA, and SAU41 protocols (McMahon & Firestone, 2024).

**AI Compliance Frameworks:** The program includes structured protocols to ensure that AI tools align with federal and state mandates. Compliance audits will be conducted regularly to assess whether AI tools are being used in ways that meet legal and ethical standards, ensuring that SPED students' rights are protected (Nguyen et al., 2023; Holler & Zirkel, 2008; Roschelle et al., 2024). **AI Bias Audits and Monitoring:** Routine AI audits will be established to identify and mitigate any disparities caused by AI-driven decisions in SPED interventions (Nguyen et al., 2023). These audits will ensure that AI systems do not reinforce historical inequities or perpetuate discriminatory practices (Maslej et al., 2023).

**Student and Parent AI Literacy Resources**: The program will also provide informational resources for students and parents to raise awareness about AI's implications in education, student privacy rights, and the role of AI in shaping educational outcomes (Baydar, 2022; Gamal, 2023).

**Continuation Program Services Professional Learning Communities (PLCs) for AI Ethics**

The program aims to foster collaboration and ongoing professional development. AIEIP will establish PLCs where SPED educators, administrators, and AI specialists can engage in meaningful discussions regarding ethical challenges, share best practices, and work together to enhance AI implementation strategies. These PLCs promote continuous learning and help ensure that ethical AI practices are incorporated across the district (Holmes et al., 2022; McMahon & Firestone, 2024).

**AI Support Groups & Resource Hub**

The initiative also features AI support groups and a digital resource hub designed to provide continuous assistance to educators. These offerings create an environment for educators to address challenges related to AI implementation while accessing the most current materials and resources concerning AI ethics and compliance. Central to this service are peer support and mentoring, enabling educators to collaborate and learn from one another (Davis et al., 2021; Baydar, 2022). By providing these resources, the program not only aids in ethical decision-making but also reinforces the PLC within the educational community (Bhosale & Jamsandekar, 2022).

**Micro-Credentialing & Certification**

Continue to encourage participation and acknowledge professional development, AIEIP aims to provide micro-credentials and certifications. Educators can obtain certifications in AI ethics and compliance, which serve as a tangible testament to their dedication to responsible AI use in SPED. These credentials encourage ongoing growth and ensure that educators are well-prepared to tackle the complexities of AI integration (Maslej et al., 2024). This strategy has proven to enhance teacher engagement and establish accountability mechanisms for professional learning (Nguyen et al., 2023).

**Why AIEIP Is Essential**

**Data Privacy &**

**Consent:**

Provides transparent frameworks for ethical data collection **Stakeholder Understanding:** Addresses awareness gaps through comprehensive training.

**Human Oversight**: Maintains humans in the loop for critical decision-making.

**Equitable Access:** Ensures fair distribution of AI resources across student populations

**Full Case Study**

**Mathematics Education in Greece**

**Challenge:**

Students with special needs struggled with math concepts due to traditional approaches

**AI Implementation:**

Created personalized worksheets with ChatGPT

Incorporated students' personal interests Tailored for specific learning disabilities Aligned with curriculum requirements Created 'mathematical familiarity

**Significant improvement in test performance and math engagement**

*I felt familiar with these problems... I saw the role they have in my everyday life.*

**-Student with Dyslexia**

(Rizos et al., 2024)

**Ethical Considerations:**

Risk of algorithmic bias in student interest interpretation

(Rizos et al., 2024)

**Challenge:**

**Active Reading Systems in Japan**

**Why AIEIP Is Essential**

**Data Privacy &**

**Consent:**

Provides transparent frameworks for ethical data collection **Stakeholder Understanding:** Addresses awareness gaps through comprehensive training.

**Human Oversight**: Maintains humans in the loop for critical decision-making.

**Equitable Access:** Ensures fair distribution of AI resources across student populations

**Full Case Study**

Resource room limitations in providing individualized reading support

**AI Implementation:**

Learning Evidence Analysis Framework (LEAF) system for active reading

Real-time learning analytics Monitored reading behavior patterns Visualized learning processes Enhanced stakeholder communication

**Early intervention detection and improved parent and teacher insights**

*Being able to see what he is doing through learning logs helps me understand him.*

**- Parent of Student with ASD**

(Toyokawa et al., 2023)

**Ethical Considerations**

Data privacy concerns and consent challenges

(Toyokawa et al., 2023)

Return to the Table of Contents Page
