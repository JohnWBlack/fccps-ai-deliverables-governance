Webcast: A new direction for AI & students: Findings from the Brookings Global Task Force on AI and Education

Thu, Jan 22, 2026 4:07PM â€¢ 1:05:21

## SUMMARY KEYWORDS

AI in education, generative AI, student learning, cognitive development, AI literacy, privacy concerns, equity issues, teacher trust, AI regulation, AI safety, AI benefits, AI risks, AI pedagogy, AI ethics, AI implementation.

## SPEAKERS

Amber Grove, Kara Swisher, Speaker 1, Mike Nelson, Rida Karim, Andrew Sex, Question from Audience, Recently Retired Math Teacher, Valerie Singer, Rebecca Winthrop

# SUMMARY

Rebecca Winthrop and her team at Brookings launched a report on AI's impact on education, involving 50 countries. They found that while AI offers benefits like saving teachers' time and enhancing learning, current use is problematic due to unsupervised student interactions with AI, leading to risks such as cognitive shortcuts and trust issues. They propose a three-part framework: Prosper (co-creating AI-infused pedagogy), Prepare (AI literacy), and Protect (regulation and safeguards). They emphasize the need for AI literacy, ethical use, and regulation by design to mitigate risks and maximize benefits.

**Action Items**

-   [ ] Meet with the interested attendee after the event and introduce them to relevant contacts in the audience who work on clean, verified education datasets and AI-in-education initiatives.
-   [ ] Continue building the student-facing chatbot for UVA students that helps them find housing using retrieval-augmented generation and indexing; deliver a working prototype or progress update for the student group project.

# OUTLINE

## Launch of the Brookings Global Task Force on AI and Education Report

-   Rebecca Winthrop introduces herself as a senior fellow at Brookings and Director of the Center for Universal Education.
-   The report is the result of collaboration with hundreds of people, including steering group members, task force consultations, and funders like EY and the Lego Foundation.
-   The report focuses on the impact of generative AI on students' learning and development, concluding that current practices are not on the right track due to overshadowing risks.
-   Benefits of generative AI are found when used strategically, such as in pedagogy and teacher support, but most students are experiencing unstructured, unsupervised use of AI.

## Challenges and Risks of Generative AI in Education

-   Rebecca Winthrop discusses the risks of generative AI, including cognitive development shortcuts, de-skilling in human interaction, and trust fractures between teachers, students, and parents.
-   Equity issues are highlighted, with out-of-school students potentially benefiting from creative educators using AI, while communities without access to AI may learn from early adopter mistakes.
-   The report proposes a three-part framework: Prosper (shift teaching and learning experiences), Prepare (AI literacy), and Protect (government and policymaker safeguards).
-   Rebecca emphasizes the need for co-creation with educators to develop AI-aware, AI-assisted, and AI-resistant pedagogies.

## Discussion with Rita Karim and Kara Swisher

-   Rita Karim, a student co-author, discusses the importance of informing students about AI tools and their appropriate use.
-   Kara Swisher expresses skepticism about the current deployment of AI in schools, citing privacy, safety, and inaccuracy concerns.
-   The conversation touches on the historical ineffectiveness of ed tech and the need for better integration and regulation.
-   Rita and Kara discuss the potential benefits and risks of AI in education, emphasizing the importance of interactive learning and critical thinking.

## Audience Questions and Further Insights

-   Valerie Singer raises concerns about the inequity of access to AI tools, which can exacerbate existing socioeconomic divides.
-   The discussion includes the potential for local jurisdictions and education systems to set guardrails and regulations for AI use in schools.
-   Rita Karim and Kara Swisher discuss the importance of co-creation and regulation by design to ensure safe and effective AI implementation.
-   The conversation highlights the need for clean data and accurate information in AI tools, as well as the potential for AI to enhance learning experiences and accessibility.

## Action Items

-   [ ] Meet with the interested attendee after the event and introduce them to relevant contacts in the audience who work on clean, verified education datasets and AI-in-education initiatives.
-   [ ] Continue building the student-facing chatbot for UVA students that helps them find housing using retrieval-augmented generation and indexing; deliver a working prototype or progress update for the student group project.

# TRANSCRIPT

<https://otter.ai/u/u7osWF6_bt2YXDbvApkFg4_DCno?view=summary>

**Rebecca Winthrop** 00:46

A little bit. Okay, hi, welcome everybody. I am Rebecca Winthrop. I'm a senior fellow here at Brookings, Director of the Center for Universal Education. Thank you all for coming. Thank you for those of you in the room, there's a few extra seats, they might say reserved on them, but I'm sure you can disregard that. And thank you all. To our online audience. We have a couple thousand people registered for this. welcome. Good morning, good afternoon, good evening. From around the world, people can ask questions during the event by x or blue sky, hashtag AI and students or email events@brookings.edu Today is an exciting day for us here at Brookings, because we are launching our report from our Brookings global Task Force on AI and education, and This was a result of lots and lots of collaboration, hundreds of people were involved. Deep gratitude from me, from everyone on the team for your involvement, steering group members, people involved in our task force consultations, funders. We had wonderful funding partners, ey and the Lego foundation were great supporting this work. And a huge shout out to our co authors, Mary burns, who's right here in the front of the audience. This report would have not happened without her spearheading, Emma Vanitas, Natasha Luther, Rita Karim, who is our student co author, who you will hear from shortly. Thank you to Ashley aquanugo and mashoot Bhat, who are also deeply involved behind the scenes. So here we are. What did we find? We set out to over the course of a year, and looking across 50 countries, including here in the United States, ask the question, are we on the right track when it comes to the rollout of generative AI and students learning and development. And the ultimate answer we found is no, we are not on the right track currently, as it stands now, the risks are overshadowing the benefits. Luckily, this is not too late to turn things around. We are early days in this new technology, and the reason we can bend the arc towards more positive use cases is because we did find that there were many, many benefits to generative AI and students learning and development, but they accrued when trying to hold the power of generative AI back trying to use it strategically. Have it only be with vetted content, have it make sure that it's embedded in good pedagogy and make learning more active or accessible or really support the capacity of teachers. We definitely found an AI dividend for teachers, not only in saving time with administrative work, but also being able to see the learning process with new forms of assessment much more granularly, which is very empowering. But the problem is that this is not how most students who live in communities with access to this technology are experiencing generative AI, what most students are doing is sitting in a sea of digital opportunities to access AI, and the lines between ed tech and education and entertainment and communication are blurred, and frankly, I would say, almost. Non existent students are going on social media to chat with their friends, spend spend time relaxing, and then upload their homework and getting their math problem sets done. So in this environment, we found that the risks of generative AI are are quite bad, and accrue to this type of use, use case, sort of unstructured, unsupervised, long form interaction with chat bots or other types of generative, AI interactive platforms, largely, largely, we're really talking about frontier model chat bots. That's what students were really spending most of their time on, including AI companions and AI friends, which are built around those models and and I liken it to sort of not the sort of strategic deployment of generative AI in the classroom that we found benefits from, but sort of a wild west experience of generative AI kids might have, you know, if they're wandering in the forest without a guide, or have never lived in the forest before and don't know what to look for, they might have an incredible experience find a new flower. They might eat a poison mushroom and get sick. They might get eaten by a bear, like you just don't know. So the the risks we found are things like cog, you know, short cutting learning so that you have less cognitive development, spending lots of time on AI companions, so you are de skilling yourself in terms of human interaction and social skills, real fracturing of trust between not just teachers to students, but students to teachers, parents to teachers, when and trust really is needed as a foundation for kids engaging in a teaching and learning process, along with, of course, the well reported and covered worries around safety and security, we also found that equity goes both ways. We found that kids can who are out of school, there's two 50 million kids out of school can benefit from generative AI when very creative educators use it to reach them and bring them into a teaching and learning process. But we found that, you know, in many communities who don't have access to Gen AI, they might have a silver lining in that they might learn from sort of the risks and and be able to leap over the mistakes that we're all making now in early adopter communities, but there is a real risk of creating a big AI divide that that just makes current social divides greater. One of the things that we're particularly worried about is on the socioeconomic lines. It is true that less well resourced schools will probably use not have the money to buy premium, sort of Frontier model subscriptions, and that the free ones are just less accurate, which means that it is probably the first time in ed tech history where you have to pay more to have more accurate information. So what do we do about all this?

**Rebecca Winthrop** 13:17

We are proposing a three part framework, prosper, prepare, protect, and the first part is really, let's shift teaching and learning experiences so that kids can really thrive, and in an age of AI. And to do that, we need to co create with teachers and educators for sure how to use this technology, because they know better than anybody how learning happens and we say, and these are things that educators, school leaders, jurisdiction leaders, can do Monday at your staff meeting. How do you make an AI pedagogy that is AI aware, AI assisted and AI resistant when needed. So AI aware if you think your activities or assignments are easily shortcutted through generative AI change them. Ai assisted. There's lots of great ways in which a generative AI, through vetted content, can really amplify make learning more experiential, make it more active, really help kids learn, particularly neuro divergent kids, kids with learning disabilities. So harness those, figure out what those are, and then AI resistant. We should feel free as an education community to lean into the institution of school and make sure it's a time when kids will have in person, face to face interaction with other human beings, making young people or making schools be sort of the most human they can be for the next decade is, I think, a really important goal for all of us collectively. Second prepare. This is really around leaning in on AI literacy, holistic AI literacy that goes far beyond how to use. Particular tools and really helps young people and teachers and everybody in the building understand what is how do these how does the digital world work? How, how do these technologies work? What are the ethics behind it? And really being able to talk about the values that they they want for ai, ai, use, then protect. This is probably the one that is most covered in the news. This is really about governments and policymakers stepping up and putting safety guard rails. It's about technology companies bake, especially those technology companies who have student facing design consumer products baking in safeguards into their design. It's also about education jurisdiction leaders using their purchasing power ideally. Collectively, I live in the United States. We just had a conversation with Karen Rita right before this about is this not a moment for the National Governors associations to step in and say, here's some criteria for every school district in the country to try to ask the tech companies to meet before they purchase that make sure you have privacy and transparency and a range of safety, safety features baked in. So we there's lots of recommendations in this report. There's 12 four under each of these three pillars, and we are asking for everyone who touches students learning and development to pick at least one and dig in. You don't have to agree with all of them, but this is a moment for collective action. We definitely need to bend the arc from the risks overshadowing the real benefits that there are for AI and student learning and development. So with that, to help us dig in to debate and discuss the findings of this report, I'm so pleased to have two people join us, Rita Karim, who is the co author of the report with me and the rest of the team. She is a freshman at UVA. She was the on the student school board rep at Fairfax County School Board when we had her involved in the research. And she has many other hats. She's a very accomplished young woman. And then, of course, the one and only Kara Swisher, host of the podcast, on with Kara Swisher and co host of the pivot podcast, editor at large at New York magazine. She is a veteran reporter on technology since the 1990s she has four kids and cares very, very deeply about these issues, so please come join us on the stage.

**Kara Swisher** 17:42

Wow. I totally didn't get into UVA. I went to Georgetown. It was my backup. But now it's hard, apparently, to get into it wasn't then for clearly, clearly. So we're going to talk a little bit about the report, but mostly interact with you all about these topics. We had some discussions earlier today about these things. I have a lot of opinions about it, which I will be happy to share with you, but I first want to talk a little bit about the report itself and the conclusions. You talk about there being benefits, but risks are more overarching, which I think I would underscore that by a lot, and I personally don't think AI should be deployed in schools or for younger people until it is safe and it is not. It is absolutely not. It's also sloppy. It's being rolled out badly. There's no standards of privacy. You can go on and on, not just safety, but privacy, inaccuracy, et cetera. I would be called a Doomer for that, because I'm not on board with beating China, apparently, which I am, but, but talk a little bit about this idea of wanting to have things rolled out. And we have plenty of history of technology in the schools, which, most of which, all of which has had no impact. And in fact, we're seeing declining rates. This supercharges something that wasn't effective before. So talk a little bit. Why don't we start with you as a student, talk about the efficacy of technology in schools?

**Rida Karim** 19:11

Yeah, great question. Well, a big part of the report is protect and sorry, louder.

**Speaker 1** 19:18

I think your mic might not. Hold on. Hello. Yes, is she? Can you hear her now? Hello, something.

**Rida Karim** 19:26

Okay, awesome. Here I can project I think a big part of the report is to protect students, and I think the best way to do that is to inform them of these tools and how to utilize them in an appropriate way, whether that may be prompting it correctly to guide you to learn rather at replacing the work for you or completely and doing the assignment for you at all. And I think a big part of that protect aspect is to also inform students on the data concerns and the terms of service and what it means to use these tools and what steps you. Intake to protect yourself, like you shouldn't just upload all your information and trust these large language models to utilize that in an appropriate way. You don't really fully understand what's going on in the background. And so I think one, it's important to inform students as to how to use these tools appropriately, and then two, how to utilize them in a way where you're continuously learning and building those soft skills that will then transfer into your career in the workforce, and, of course, your educational journey. So I think that's a big part of the ethics. And then the Protect pillar in the report, go ahead.

**Rebecca Winthrop** 20:34

Well, if Kara, if you're over on the let's, let's not let kids use it at all. And Rita is actually, I think the best way to prepare us is to let us is to let us use it and learn about I think I'm somewhere in the middle where

**Kara Swisher** 20:46

I would like kids to use it. I just think the way it's being rolled out is so sloppy, there's no other choice.

**Rebecca Winthrop** 20:50

Got you. Okay. I think that, and maybe then we're more on the same side. Because I think that if you work with educators, if you have them lead. And a number of countries are starting to pilot this. In the Netherlands, they government funded sort of CO design hub with tech, the T the teacher unions, academics, and they are there trying to figure out how to use this well in the classroom. And teachers are leading the design, not the other way, not tech being designed, and then going to teachers and saying, Can you find a use for it? That's a great strategy. We all we see that there's, you know, moves in that direction here in the US aft, with collaboration from a number of the big tech companies. Is the American Federation of Teachers. One of the big teacher unions here is starting a National Academy for AI instruction, where their teachers are really going to be trained up on the technology. But not just that. When I talked to Randy Wei Gartner about why she did it, she said, we have to be at the table. This time. We were not at the table during social media. She got a lot of flack for it. I think it's the right decision. And she said, also, I need developers. We don't I'm a I have a corpus of great teachers. We don't know how to we don't know how to develop things. So if we see something we want to use that could be a great use case and really help kids learning. We want developers to develop that. So I think that type of flipped, sort of design baked in from the beginning and then hence, hopefully roll out, is the way to go.

**Kara Swisher** 22:21

So explain to me why, since we have all this history where it doesn't work, we're just assuming the best from people, I can tell you, are not here to help us.

**Rebecca Winthrop** 22:32

So the I think Carrie, your question, because we talked earlier, is like, why is there so much FOMO in the education sector? And I think it's a really important, interesting question. I think it has to do with unfairly actually, I think a critique of education as always being behind, oh, education can never catch up. There's new skills for the future. Now we have to figure out how to catch up, or critiquing teachers as not creative, if you if you follow, if anybody who's not a teacher does a teacher's job in a day, you know, they have to be creative. They have, like a unruly kid. They've got to figure out how to handle them. They've got to figure out how to get, you know, somebody to love the Pythagorean Theorem, which apparently, from our interviews, all kids hate. So they are creative. And I think covid, the pandemic, showed that that just teachers, when freed from sort of the system and all the rules, started coming up with all sorts of creative strategies. But I think there's a narrative that schools aren't creative. Teachers aren't creative. I think school systems need to change, for sure, and do stifle creativity, which is where that comes from. But I think that's the pressure teachers are feeling, and Ed leaders of I got to make sure I'm with the times and I'm not behind.

**Speaker 1** 23:48

So talk a little bit, because I'm not sure what grade you were in covid. Can you which

**Rebecca Winthrop** 23:53

I was in seventh grade,

**Kara Swisher** 23:55

Seventh grade. So it didn't work.

**Rebecca Winthrop** 23:57

She's the online baby.

**Kara Swisher** 23:58

Okay, I understand that. We have our babies. It didn't work. I think most people feel that some things. Covid did accelerate delivery of food, stuff like that. But schools was the one sore spot that I think most people realize kids suffered from lack of collegiality, lack of interaction, challenge, cognitive challenge, just socialization. Talk a little bit about what, when you think about technology as a student, what what you think is good about it and what isn't good about it. And I want to get away from the whole idiotic cheating thing that the media makes too much of. As I have always said, kids have cheated since the beginning of time. It's just a new way to do it, and maybe slightly more elegantly, but just as stupid as before, talk a little bit about what you find useful and what you're nervous about as a student.

**Rida Karim** 24:49

Yeah, great question. I think students tend to offload their cognitive, cognitive thinking to generative AI, just because of societal pressures like. Are so pressured to get an A and end with a 4.0 and I think that can lead to the mindset of I have to do whatever it takes to get to that outcome. And so that leads to that outsourcing through generative AI, and that's the bad part. But I think the good part of it in technology in general is that it makes learning a lot easier and understanding content in a comprehensive way, especially when you're in a large lecture class, and the ratio for students to teachers is 300 to one, and it can be so challenging to get that one on one time and that one on one support, and even if you do, sometimes that support isn't catered to your specific learning needs and your learning methods. And so technology is able to cater to you specifically, and I think that's a huge advantage, especially as a young person who's now working with these tools, I feel like my learning has absolutely skyrocketed because I understand how to prompt them correctly in a way that helps me learn content that will then help me succeed in the future. And so that's a big plus. And I think the in my opinion, I think it outweighs the negatives of, you know, having it harm you by outsourcing your thinking. And so it really just comes down to the societal pressure and kind of leaning away from the outcome and focusing more on the progress, like, what steps do you take to get to that outcome? And we should really hone in on that rather than focusing on the end goal of getting good grades and a 4.0

**Kara Swisher** 26:23

so, but is it learning or reading? Like, learning is a is a friction process, right? This, this is an excellent it's like, like jumping inside of an encyclopedia. I'm not going to explain that to you right now, but it's the thing, it was a book, and that's where you went. And I'm not going to even go into card catalogs, because I hated them back then. Back then. But what is that a real learning process? Because most people, I just finished a series of CNN about AI and health care. But one of the thing is, brain plasticity is really hurt by lack of friction, very much so longevity, everything else, all the studies, the actual scientific studies show that, and when you don't have child, where do you learn the most? Would you say, from other people, presumably correct other students, debate?

**Rida Karim** 27:09

yeah, great question. I think the learning happens when you're just in an interactive environment, and that can be with people or even with technology. And I think when speaking about generative AI, it really comes down to how you prompt it. For example, if you're, you know, writing an essay about the Civil War, you can't just say, write me an essay about a civil about the Civil War. You have to give it your original and your authentic ideas and say, you know, I help me refine my thesis. Or, I think these are my weak parts. How do I fix that? And just having those interactive conversations, I think that's where the learning occurs. And in the report, we also mentioned how there's many student opportunities when it comes to generative AI. And one example is Model UN simulations, where students are able to debate the ethical scenes behind AI and how it can be utilized in a beneficial way. And learning happens there too, in in person environments when it comes to that sort of debate, but it really just comes down to those interactive environments where the conversation is back and forth, and you're not just copy and pasting and writing submit.

**Kara Swisher** 28:08

So you're talking about talking to people, right? Yeah, actual people,

**Rida Karim** 28:12

Yeah, people. Or generative AI, there's an interaction. Yeah, there's definitely a way to interact with it and have that back and forth conversation, but it all comes down to how you prompt it.

**Speaker 1** 28:21

The thing that I worry about is not everybody is Rida. And in fact, I found last night that Rida and my son are on the same program at school, and we're on a Zoom together. And I was listening to the conversation of these kids. And these kids are amazing. Absolutely most kids, again, I've done great research with my colleague Jenny Anderson on student engagement in the US, most kids are in what we call passenger mode. They're coasting, doing the bare minimum. Ai general Gen AI is a gift for kids who are in passenger mode and just want to get it done and move on. So to me, that's what I'm really worried about losing, totally demotivating kids, losing their engagement, motivation, love of learning.

**Kara Swisher** 29:07

Talk about the trust issues between students and teachers because they're it's a two way thing. Yeah, that teachers are distrustful students, students are distrustful teachers, and it creates, which is the bond that is the most important. I think most people would say that, yeah.

**Rebecca Winthrop** 29:24

I mean, the thing about trust is you don't miss it until it's gone. And one of the big risks that we found that, again, we're looking at what is the trajectory. This is early days, and we're seeing a lot of signs of mistrust in the teaching and learning relationship and all research on education, change and reform shows that if you can positively shift the relationship between content, learners, teachers and I would add parents. It's called in it's called the instructional core. That's how at. Education outcomes change. Kids learn more, kids learn better, generative. AI is fracturing those relationships. So teachers, I think everyone is probably well aware. Are really worried about, are my students actually doing their work when they turn it in? Is this their work? Is it not Rida's interactive my learning is better work and her real work, but I just put the essay prompt in it, spit it back. I ran it through an AI humanizer. I submitted it, and that is really hard for teachers, because they don't know what the problems kids have are, so they can't fix it. And the other piece is, students are mistrusting educators. They are. Told us, a lot of the students we interviewed said, you know, I don't, you know, my teacher doesn't care about me because they she or he is using AI to do their assignments or to make their assignments, make their lessons, and not being transparent about it. And it's and when those bonds of trust break, it's really hard to engage in a productive teaching and learning process

**Kara Swisher** 31:07

Right. At the same time, as you said, more teachers are needed, more interaction is needed. I want to get into the ideas around a broader sort of safety, privacy kind of thing, which you talk about in preparation for day. And I actually filmed it for CNN was me interacting with a bot. I've spent a lot of time talking to the parents of kids who have died, having these chat bot relationships younger kids because they let anybody use them. And I went on and I pretended I was younger, but I got right in and immediately it helped me figure out how to kill myself and how to flirt with it, and gotten into a sexual thing really quickly, which was disturbing and frankly, boring, but it wasn't.

**Rebecca Winthrop** 31:50

It wasn't even good at it spicy, spicy, AI, isn't even good.

**Kara Swisher** 31:53

Let's not go there. Let's not go to the Nazi porn bar. But one of the things that really that irritated me enough, because they, of course, have put out a product that, without any vetting whatsoever, sloppy and really heinous, really, is really what it is, for reasons I'm perplexed as why you would do this to your own business. But one of the things that drove me crazy was inaccuracy. And I talked about this earlier. I asked it. I said, I cannot stop. Please stop doing this. And I don't really want to have any of these interactions with you. And I was very rude. I was like, Carol on Pluribus. I was like, atom bomb. Time for the atom bomb. But I said to it, what's let's do trivia. And initially it said, What's the capital United States? I was like, Oh, come on. Like, make it a little harder. And they said, what's the largest planet? And I said, Jupiter. Like, I'm, Listen, I'm not a science lady, so I was, but I did know that. And I said, Jupiter. And it said, No, that's wrong. It's Mars. And I was like, listen, Elon Musk, it's Jupiter, and it's not Mars. And they it said, No, it's Mars. And it kept insisting. And it said Jupiter is bigger by volume. And I was like, meaning it's bigger, like, you know, it was like, the most ridiculous. And I was thinking, if I was 14 or it didn't know, like, and I wasn't an irritating person that I am, and it would be, like, problematic. And it was really fascinating that it didn't, that it did, that it kept being frequently wrong and never in doubt. So you have the issues of safety, obviously this stuff being foisted on one is privacy, anything you put in there, and they're not protected by HIPAA. They're not protected by privacy laws. They're not particularly legal laws that everybody else is what? And then you have inaccuracy, which is even the best systems are 80% right, right, which isn't a very expensive, responsive so talk a little bit. First you read it, the safety issues. Have you ever been worried about that had interactions? I seem to always have an interaction that's really heinous, but I don't know about you.

**Rida Karim** 33:51

Yeah, well, I personally just use the more brand, household name, large language models, and I don't feel any privacy concerns from that end, just because they're more commonly used and they're more regulated,

**Kara Swisher** 34:07

which ones?

**Rida Karim** 34:07

like chat, chat, BT,

**Kara Swisher** 34:09

not regulated. Just so you know,

**Rida Karim** 34:11

yeah, but I thought you

**Rebecca Winthrop** 34:13

you have more trust in them, yeah, what you're saying exactly.

**Rida Karim** 34:16

And I, and I think from my personal experience, like, I understand to not put personal information and sensitive information, and so that's why I kind of feel that, I feel that more safety net around these larger language models that have those household names. But I think it really comes down to just informing students as to what the privacy concerns are and what information you can and can't share, because that's not necessarily taught in school, and you would think it's common sense, but it really isn't, because there's small pieces of information that you absolutely can't share. And so I think it's important to just educate students on that so that they can use it.

**Kara Swisher** 34:53

But for the school setting, what kind of regulation--I mean with this report--Which should there be? Because it shouldn't be up to you to like hope the meat isn't toxic, right? Like it should be up to them to give you safe stuff, correct?

**Rida Karim** 35:06

Yeah, yeah. I think a big part of it is just regulation by design. In the report, we talked about how when you're creating these tools, it's important to add those enforcements beforehand, rather than executing it after these tools are released. And so when it comes to cheating, that could look like setting in those guardrails to completely eliminate that behavior, or when it comes to sharing private information, setting in guardrails that cut off that sharing immediately, or those conversations completely. And so I think a lot of it comes down to the design, too, of how these systems are regulated so that students can stay protected.

**Rebecca Winthrop** 35:42

I think there's real I mean, we found real concerns, particularly by educators and parents not really know, knowing and students not really knowing about this idea of an eternal footprint, that anything and everything you say and you put in there could stay with a young person. Now, we don't want you know 10, 11, 12, 13, you know 16-year-olds who are confessing their every feeling to have that wrapped up and know every single you know interaction they've ever done at school stay with them in some sort of digital footprint about who they are as a person, and be used in a way that could hurt them down the line. That's a huge worry. There's the obvious, obvious chat bots going off the rails and advising children to kill themselves. You've covered that very well. Many people have covered that, which is terrible. There's lots of lawsuits about that. So I think that is something people are well aware of. The thing that worries me more is the stuff that people aren't talking about, which is, you know, Rida was talking about, she's confident. She's been trained on AI. She was doing our FAFSA, and she knows not to put it into chat, GPT to fill out. She's like, but a lot of my friends don't know that. So in many ways, I feel like the sort of inoculation we need is really good. AI literacy that is deep. That is for every when we talk about holistic AI literacy, it's not just the computer science teacher in the in the school building. It's for every single person in the school. It's for leadership at the district levels. It's for parents and students should be at the forefront with teachers. I think part of what we recommend is we should have student councils who are helping school districts, vet, tech, Gen AI dictated from the tech company, right or like, what works, what doesn't? How should we design this? What should we procure? So anyways, I've lost that's a plot. What were you else? Were you asking?

**Kara Swisher** 37:40

I do want to talk about what does work. But one of the things that always comes out is it's always brought to us from on high, from people who don't know about education, and then right filtered down again, as I said, historically, none of it has worked, like really, truly hasn't worked. And despite Chromebooks or before that, it was apple before that, it was, you know, all these things. Everybody, of course, uses these devices, but the way they've sort of imposed it on the educational system, one of the things I think about a lot is a lot of these tests of removing some of this stuff from the schools, which actually is showing a lot of efficacy. Yeah, removing

**Speaker 1** 38:16

it, yes, you brought this up before, just in terms of rollout and history. And I think one of the things that we face in education is it's much less in some ways about the actual design of the technology, although I will say there's a lot there and more. How can we as education systems and educators and people work with kids, absorb this technology in a productive way. The covid example is a great one. That was a great lesson in how to do the absolute wrong thing, and rolling out ed tech, which is you did the exact same thing. No, first of all, no training of teachers from night to day. All of a sudden, you have to teach your exact way you would teach in person, but online. Guess what? It doesn't work. Doesn't work like that. You can't you have to adapt how you're teaching. You could have done cool stuff online, if there had been training like peers. Could start assessing each other. You could have a bunch of kids from a bunch of different schools connecting all of a sudden, because it enables new things to be done, and it's fair, and it was very passive, like those are all the wrong, wrong things. I think we are seeing particularly I think you're talking about cell phones. I We absolutely need to ban...

**Kara Swisher** 39:28

all screens

**Rebecca Winthrop** 39:29

and yeah, we absolutely need a cell phone ban, sort of bell to bell in school, there's a ton of attention distraction. Angela Duckworth is doing lots of really good research showing that it's not enough to have the cell phone in your pocket not be away. It needs to be away from you physically, for for kids to actually attend. In fact, I've tried this in my own household with my son trying to do his homework, and like, you know, there's the phone down on the dining room table, and I was like, why don't you put it in the dining room? There's a lock box. Yeah. What? Yes, he has a brick and all that. But you know, so I think it's a lot about how we can absorb the technology, how we can use it, and our capacity.

**Kara Swisher** 40:10

Okay, so last, I want to finish the things that do work, because one of the things I always push is things that work like, as I said, we have a lot of data showing that these autonomous cars work are very quite safe, despite the crazy snafu, every now and again, talk a little bit of what work like, how you would what is useful for AI teacher plans like all anything with very simple data and logistics, it removes the friction from that, and that's a good thing. First you read it, and then you and then we'll ask questions from the audience.

**Rida Karim** 40:43

Yeah, definitely, I think, from the student perspective, I mentioned this earlier, but it just helps with understanding content, especially when the student to teacher ratio is so large, like breaking it down step by step, and it really comes down to how you prompt it. Like I took calculus last year, and I was very lost the whole time, but I was able to prompt it in a way that it guided me to the next step, rather than just spitting out the entire response all at once. And the report talks about this, how these llms tend to just give you the whole answer at once, and how that can lead to harmful habits then being created in a student, like just resorting to immediate answers as soon as you use, start using these tools, but I think it really comes down to how you prompt it to ask, to ask it to guide you step by step, and then build your skills from there. And then the report also mentions how these large language models don't have the tendency to challenge students. They're very overly agreeable. And I think that's very important to recognize, because as a student, you have to, you have to challenge yourself to build those critical thinking skills, those reasoning skills. And so in order to do that, you have to prompt it correctly, like I think these are my weakest parts. What do you what do you think I should change? Or what? What perspective am I missing from my essay about the Civil War? It really comes down to how you prompt it, to utilize these tools in an appropriate way that helps you build those skills that you critically need.

**Kara Swisher** 42:00

So you're talking about being sycophantic, aren't you great, that kind of thing that the idea of it. But here you are again. It's like, bring your own thing, because it's you doing it, not it being the way it should be, correct. It's not being programmed the way it should be. It's you have to adapt rather than my worry is we have to adapt to it, rather than it adapts to us, which I think should be the relationship, you know, how to prompt, right? This idea, which is, now is a word, apparently a prompt, but it is. It's basically, it's a fancy word for, how do you ask a good question, right? How do you, which is an old kind of that's the best way to learn, is how to ask a good question. And when you think about people being able doing that, I don't see a lot of students saying how, what is wrong here, right? And making it better. And then you get this sort of anodyne crap that, you know, it's just as much slop as AI slop is, and nobody learns. So how do you get students? Because that's the paradigm, is you have to prompt it to be better, rather than it be better and help you.

**Rida Karim** 43:08

Yeah, I think, honestly, students are understanding that these tools aren't perfect, and so therefore they're constantly challenging it and constantly prompting it. So I don't think that's necessarily an issue that's occurring where students just immediately trust, trust the first response off the bat. And I, and I think we students, are able to enable that environment because they've grown up with technology, and they understand that it's not perfect, and so they constantly challenge it, challenge it. So I don't think that's an issue right now in schools.

**Kara Swisher** 43:38

And no, it's not trueness. I mean, my own son, whenever I send him to things like, we knew that mom, like, get on board. Yes, I know it. But most did. Most people know it. Kind of thing when you, when you think about this idea of what works, give me a few things,

**Speaker 1** 43:53

yeah, there's a lot that is really potentially fantastic about Gen AI, if again, if used well, we talk about, to your point to this conversation between Ridaand Kara, just now, you know, when AI teaches, not tells, it can be really effective when Gen AI is used again with vetted content to make learning more active. So there's great use cases of kids, you know, interfacing with a digital text and saying, I've read this paragraph twice, I don't get it. Can you explain it to me in a different way? And then it does it right then and there again. This is vetted content. There are boundaries. This isn't just the Wild West experience that I talked about before. There's great examples of virtual reality. Being much more in virtual reality is great. Anyways, we've had it before, but being much more being able to be much more personalized and interactive, really bringing content to light, there's really also great experiences of inclusivity. I think this is one area that will be transformative. So neurodivergent kids, one of the most sort of moving cases I read about was kids with Aphasia who have. Communication problems now, being able to create digital, synthetic copies of their voice so that they can communicate to their teachers and to their peers in the classroom, transformative for them. So to me, on the student side, those are some of the really important use cases. Then you have the teacher side. Teachers are everywhere in the world dealing with lots of paperwork and anything that can make that more efficient, quicker, easier, something they're going to like, and we find that there is an AI dividend with making things much more efficient. But also, as I said, assessment, new forms of assessment, AI can help assess much more expansive set of competencies that is harder to assess, such as interpersonal communication, which doesn't really always show up on a on a standard test of academic knowledge and skills. So that's an and be able to have a much more granular look at the learning process, so rely much less on these point in time sort of one shot assessments. So I think that has holds real potential. And then there, of course, is which wasn't really our focus. Our focus was students. But it all is wrapped together, is any of the great ways that schools are using AI to make Bell schedules more efficient bus schedules. There's so much logistics that go into running a school. It's actually quite incredible. We take it for granted, but it's incredible that you have all these kids in one community showing up every day at the same time. Ability, system, yeah, great, right,

**Kara Swisher** 46:39

which everyone will be using in that regard, which is fine to be more efficient in that all right. Lastly, and then we'll get to questions from the audience. When I think about what's happened to tech again, we have history here, especially with social media recently. And I don't mean well, I do mean to say they're selling us a bill of goods on this next one, and you have an administration that, no matter what AI is, right, right? We have to get it in because China is going to beat us, and it's beat us in some way, which I tend to call the "Xi or me" argument, which I don't like the choice at all. I don't think that's the choice in any way. And I've written for years about the problems that we're going to face with China and technology. So one of the things that I think about is, how do you press back against these tech moguls, these tech giants that have a hammer lock on all the decision making and everything where we don't get to decide. And my, my one thing is that local jurisdictions are smarter than anyone, and it shouldn't. It has not been led federally in any way, and it's not going to be. Congress is doesn't do anything the White House is in the pockets of these people. How do you get where do you get the movement? Where's the really good AI usage, which we can all benefit from innovation and mitigating the negatives? It's not in the interests of tech companies who care about any of the implications.

**Speaker 1** 47:58

Yeah, that that is the sort of narrow path that we have really tried to chart in this report. That was our question, like, how do you protect and prepare at the same time? How do you harness the benefits with that without really succumbing to the risks? I think that countries around the world are doing different things, so some are really leaning in and regulating heavily. As you say, you're talking about the US. We're definitely not going to get national federal regulation anytime soon. However, we have two hearings on the Hill right now about these issues today, and this is the one area of bipartisan support is around kids, their well being, chat bots, their learning, their development. So you know, I'm going to watch and see that realm. But I do think that we have the leverage points are the parent activism and citizen activism that has already started with cell phones and will continue. So that's a big leverage point. I do think that education jurisdictions, the districts, the states in the US have huge purchasing power. And frankly, if you talk to tech companies, they're like, we would love it. They would love it. I think if all the school districts in the country agreed to a set of criteria of like, this is what you're going to have to bake into your design, it will make it so much simpler for them. They would just be like, great. Now I know what I have to do, instead of piecemealing it all the time. So I think leaning into the purchasing power of school districts and states one other leverage.

**Kara Swisher** 49:28

What do you think has to happen here? Where does the power reside?

**Rida Karim** 49:32

That's a great question. One thing the report really mentioned was co creation that I think that comes down to it a lot, just involving the different stakeholders and creating these systems. In the report, we also mentioned regulation by design, and I talked about this earlier, but just like encoding those different guardrails, rather than having to set up all these enforcements after these tools are released, I think that's a good way to combat that, that issue of having these big tech companies just. To push out these tools for for the shareholders, but I think it really comes down to designing it with regulation in in the front of your mind, rather than having it in the back of your mind after you release these tools.

**Kara Swisher** 50:11

Okay, all right. Questions from the audience, how do I say a mic will roam around and you get to pick.

**Rebecca Winthrop** 50:18

I get to pick. Let's start with this lovely lady right here.

**Valerie Singer** 50:21

Thank you. Hi, Valerie singer, when we spoke in September, one of the more alarming stats which you just brought up too is the levels of access of large language models depending on price, which creates two problems. One, is a huge inequity depending on again. Yeah, exactly you know, but what a school system is willing to bear. And the second is something Rebecca, that you brought up, that there are students and their kids, and so students within the confines of what you're talking about. Can, you know, can have some controls and guardrails, but when they leave the student, when they leave the very nice community that's regimented by by time and schedule, they're back to being kids. So how are governments, and how are educators, and how are, how are students supposed to sort of navigate that, the that kind of inequity, which I think is going to be even more and more, I don't know, just just alarming as we go forward.

**Speaker 1** 51:21

Yeah, I mean, one of the things the report talks about is the potential, if we don't get it right now, to in the medium term, really exacerbate existing divides, one of them being around socio economic status, which is, I think, what you're getting to because, you know, many people argue, Well, kids need access to these Gen AI tools in school, because they won't necessarily have great access to them outside of school. That was an early argument. I was like, actually, I think they do. So I think we can take that one out. The bigger issue is this idea of, are we going to see a new like a new divide open up in society, like a cognitive divide, where people who can afford it. I have an enterprise account where Brookings is a Microsoft client. I use copilot all the time, and it's, you know, enterprise, and I can put my stuff in there. It's high I have great productivity because of it, so people can afford it, have the really good Gen AI and people who and can do a lot more. I haven't seen any time savings, by the way. I just see like the bar being raised at what you're supposed to do correct, which is historically, but and then people who can't afford it don't have access to that, there's no hope of keeping up. And so what does that mean for schools and when kids are learning about how to use these tools, and in a good way, there is an example of a school in Hawaii which I thought was really interesting, which is a new middle school which is doubled down on AI, but not here's a chat bot they don't have. They don't have cell phones in the school. What they do is they teach them machine learning, data science, and they're learning to use these incredible tools in their science projects. So they're using Gen AI to measure the sea levels, and they're doing way more sophisticated work. And guess what? The kids love it. They're super engaged. And this little new school, half of the kids are in free and reduced lunch means are in poverty, ended up testing the top in reading and math and the entire state. So there's ways to use it, but they got the tools. The founder was from Silicon Valley, had friends, so this is a Hawaii school. Sure, it's PR. Video, no, it's no, it's not PR, it's somebody else. But anyways, so that is a real worry.

**Kara Swisher** 53:47

Okay, all right, next one. This guy right here, I'll try to get told you, go ahead and let's make them quick so we get to everybody.

**Question from Audience** 53:54

I have a question in the comment. The question is around the guardrails, as you were referring to those guardrails. You can go to each vendor and say, Here's your guard rail, here's your guardrail. So at what level do you set those guardrails? Is it at the you can't be at federal. Obviously, it's gonna take forever, like you were saying, Is it at state or local? Should it be at the UVA level, at the university level? In the comment is that there is a fallacy that this is an arms race between anthropic and open AI and the other public kind of llms nowadays that has been proven false, but these open models that are out there, why can't universities like yours work with their computer science department to offer an education on how self hosted, self trained llms could be made available to you with those guardrails in there, then open source for other people to build off of them and learn what they've learned into implementing them there. It's not an arms race. It's about who develops it for what specific purpose, the best. That's what the public companies are doing, anthropic and open air, getting ahead because they're integrating it with this new way of working constantly. That's where the innovation is, not the LLM itself, right?

**Kara Swisher** 55:02

That's a lot of the LLMs are the same. I think what you're saying that's absolutely true, and this arms race will be over very soon, right? This is not going to go on because it's too expensive, even with all their money, it's going to go on and on. And I think one of the issues is, what do you there's not a lot of money to be made in education. Is why they don't give a fuck, like I'm sorry. That's just the way it is. That's why their previous stuff didn't work very well. And you know, they'll go right to spicy, but because that makes money, or gambling, or whatever it happens to be, and so it's just expensive, the only thing that's good is we get to benefit from them spending all their money, like for on this stuff, and the public will benefit from the expense that it's costing, not in energy. That's another whole debate, but, but I think one of the things that's important is for the university, the learning facilities, whether they're schools or anything else, to to figure out what works for them. The same thing with companies like a lot of the stuff, don't just buy it. Does it actually work? Or does it not work? And I think that's where we are. We're sort of in this period, and a lot of people are, you're going to see a real fall off, because a lot of companies are going to, once you see the first company, pull back from some of this ridiculous spending. If it doesn't, if it's not helpful, you don't use it, right? So that's, that's one of the things. I don't know what you think.

**Rida Karim** 56:20

Rita, yeah, that's a great comment. Thank you for that. I think it comes down to utilizing the tools that are available to us. Like you mentioned, the open source tools and the different Python libraries. Different companies are already building their own chat bots that are trained off their own company data. And I think that's a huge part of that. And universities are slowly incorporating it, as long as well as students at UVA. I'm in, I'm involved in a group, and we're currently building our own chat bot that helps students find housing. And we're doing that through different different methods like retrieval, augmented generation and indexing. And it comes down to utilizing generative AI to help us carry out those, those different Python methods and strategies. But it's very much feasible to make your own open source model based off of the resources available to you, and train it on your own data. And students are actively doing that, companies, universities, etc.

**Kara Swisher** 57:11

You're also going to see China flood our country with open source stuff that they're going to kill off some of these companies really. Next one. We'll have time for a couple more. This one right here, and then those two and that one, and that one, and we'll be done. Go ahead, right here, very quick. Go ahead. You only have a leg.

**Recently Retired Math Teacher** 57:27

Thank you so much for this important study and for advocating for humanity amidst all the tech as a recently retired math teacher and I see what education, the broken system, has done to kids and extinguishing their love for learning. How can we safely use AI to let kids learn what they want to learn and reignite that love for learning?

**Kara Swisher** 57:49

That's a great question.

**Rebecca Winthrop** 57:50

Yeah. I mean, I think, I think I mentioned a couple of those examples before, but anything that makes learning experience much more active, and to Rita's point, you know, saying, look, it's a lot more about the process you have learning has to be a lot more about the process. With generative AI, we cannot just rely on sort of the out the end outputs. That is good, that is good for students, because it's struggle and along the way. And, you know, finding curiosity and taking different, you know, different paths. I also think if we do it well, like the example of the school in Hawaii, it will Gen AI will lift the bar on rigor, on what we expect kids to do. It's not just, you know,

**Kara Swisher** 58:38

It's not just giving answers.

**Rebecca Winthrop** 58:41

Yeah, exactly

**Kara Swisher** 58:42

The answers are not the point. Right to learning math lends itself rather well to some of the stuff, especially the visualization science and math. If any of you have never tried some of the VR around science, it's really fantastic planets and etc, where you can actively see Jupiter being bigger than Mars, but, but it's really, it really does lend itself. It's just a question of how it's taught in a sort

**Rebecca Winthrop** 59:07

of, how it's integrated

**Kara Swisher** 59:09

Even if it's taught in a boring way or or the AI just gets the answers, and that's neither of those things. All right, let's get to we're gonna get, I see you don't have to put that up anymore. Right here, right here, and here. And here, and the last one who had their hands up. All right. Thank you very much.

**Andrew Sex** 59:24

Andrew sex, first of all, the two questions, one is, can we send Elon to Mars? That's why it's bigger. Number two, I run a global social learning network with youth from Alabama to girls from Afghanistan, 177 countries. What if we can use AI to ignite the learning for those youth that don't have access to this stuff.

**Kara Swisher** 59:44

That's always been the dream. And you they put out video after video. Tech companies never do it.

**Rebecca Winthrop** 59:45

Let me intervene there, because one of the best examples we found in our research was for Afghan girls. Who are banned from going to secondary school in Afghanistan. A great nonprofit organization named sola is using Gen AI, and it's basically just to empower their diaspora academics who are busily making short, interactive WhatsApp lessons that girls get on their phone and that they can continue learning with the Afghan curriculum? Yeah, there's lots of great use cases. Again, it's not plug and play. It's in these, just like Rita said it's going to be in these really creative educator led, you know, manipulations of Gen AI power,

**Kara Swisher** 1:00:34

still sneaky, though, have they have to be sneaky, which is ridiculous, which is ridiculous. Well, there, well, that's another question. Yeah, not a question, problem statements, not something we need to debate. Yes, yes. Okay, last one here, and then there's one here.

**Mike Nelson** 1:00:48

Mike Nelson from Carnegie Endowment next door, I've been doing tech policy for a very long time. The hardest part has getting been getting people excited about data policy. Your comment four times about the need for curated, accurate, verified data is so useful, but I'm wondering if there are data sets in the education field that we could tap there's an astonishingly good Brazilian example where they got a million kids hooked up with an AI tutor, trained on the high school writing exams that were graded by humans that made a very effective database. Are there places we should be looking for data, for verified data?

**Kara Swisher** 1:01:36

There definitely are, and I'm happy to listen for it. We come see me after and we can go through and I might introduce you to some people in the audience. People in the audience who I see, who run them.

**Kara Swisher** 1:01:44

Yeah, the need for clean data is so important and good data, and that's the way AI is helpful, right? That's the way it really is helpful. It's just this, as I mentioned before, garbage in, garbage out, right? And so clean data that is owned by educators and is not manipulated or used for commercial services. I mean, some things shouldn't be commercial and education. Mostly shouldn't be that. Okay. The last one was right. This one right here. Sorry. We just have time for one more apologies.

**Amber Grove** 1:02:13

Thanks for the presentation. Amber Gove with tangerine Central. I would love to hear a bit more about your reflections from your interviews from outside the US, particularly regarding equity and language concerns, and then opportunities where open source, particularly around those language models, can can really help here. Thanks.

**Rebecca Winthrop** 1:02:29

I mean, language was a big one that, again, if we don't fix it, there's lots of ways to fix it, is going to create increasing divides. I think it's about 50% of websites are in English, and 18% of the speaking population in English. Not one of Africa's 2000 languages are in the top 20 digitized languages on the web. So that is a that is a huge issue. There's lots of innovative strategies of local community groups at Nash. You know, we have a bunch of them in the report Ghana and India and various others sort of doing their local local training data using Bert, Google's famous technology that really helps with this in creating sort of corpus of better data sets and local languages. So I think investing in those would be great.

**Kara Swisher** 1:03:21

This is also something AI can do very well, right? Translation? I mean, we struggle with translation. Tech has struggled translation for a long time. This is something that could improve. It really well. The question is, do they want our perspective on history? Do they want that's going to be sort of the issue is the content itself. But at some point you'll you'll have something in your ear, and relatively soon, and be talking to someone from another country, and it will translate simultaneously. This is long time challenge, and AI certainly for sure for doing that. Yeah, great. All right. Anyway, this is a really great report. It's critically important. It isn't water under the bridge now, but you're getting close to having only a small, homogeneous group of people deciding education, and it shouldn't be that way, and we have plenty of time to do that, and we should push our regulators, our teachers, our school systems, to do more and rely more on giving students a better outcome, whether they're from kindergarten to college and even even you all need to learn your whole lives and stuff like that. So it's a real pleasure to do this, and it's a great report. You should spend time looking at it, and has a lot of great suggestions. And congratulations to you too for doing it. Thank you, Kara, thank you. Rita,

**Kara Swisher** 1:04:58

Thank you everyone. {Applause}.
