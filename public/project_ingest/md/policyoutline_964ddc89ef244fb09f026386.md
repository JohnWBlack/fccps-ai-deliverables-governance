FCCPS AI Policy Outline:

Policy Outline

Guiding Principles and Motivation

Scope & Triaging

DECISION: Limit Focus to Gen-AI?

DECISION: Cover non-academic Gen-AI risks? (i.e., mental-health risks, harassment risks)

Definitions

Incorporation of GenAI into FC Curriculum:

DECISION: Circumstances in which allowing/requiring GenAI use serves:

The goal of AI literacy

Broader learning goals

DECISION: Circumstances in which limiting/banning GenAI use serves:

The interest of AI literacy

Broader learning goals

Restrictions on Staff & Teacher Use of AI

DECISION: Teachers allowed to use of GenAI in providing feedback, evaluating students?

DECISION: Allowed use of AI detectors of GenAI work product

DECISION: Use of GenAI in high-stakes school adjudicatory documents (discipline, IEP documents, etc)

Student Use

PreK-5

DECISION: Teach AI literacy while globally minimizing in-school AI use

Grades 6-12 DECISION: Consensus on use-cases and postures

Categories of Anticipated Student Use

Prohibited w/o administrative exception

Prohibited w/o teacher allowance

Allowed unless teacher prohibits

Citation and Disclosure Expectations

Organize these by use case

Flexibility for Students with Disabilities

Protection of Student Privacy

Public Accountability relating to use of AI by students and staff:

DECISION: How to scope commitments so that they are implementable?   Think about commitments to:

Public notice

Consideration of public comment

Parental opt-out

Equity in Our Community

Not sure how to frame this… here’s one possibility:

How can we prevent over-reliance on GenAI in a way that:

Ameliorates existing inequities in our community?

Avoids creating new inequities?

How can we structure access to GenAI tools in a way that:

Ameliorates existing inequities in our community?

Avoids creating new inequities?

School Budgeting/Workload Implications

AI impacts on teacher workload

AI impacts on teacher staffing levels

Reassessment and Updating of Policy

Guiding Principles and Motivation:

Informed by evidence: The strength of recommendations should be in proportion to the evidence available.

Aligned with the goals of the IB program to foster the following five skills among students:

Thinking (critical, creative, and ethical)

Research (comparing, contrasting, validating and prioritizing information)

Communication (written and oral, effective listening, and formulating arguments)

Social (forming and maintaining positive relationships, and conflict resolution)

Self-management (organizational skills, such as managing time and tasks, and affective skills, such as managing state of mind and motivation)

Age-appropriate: The challenges and risks posed by AI use vary by age and the policy is intended to take that variation into account

Evolving:

Intended to be paired with ongoing assessment of policy implementation and a planned schedule of reassessment

Triaging AI-related issues is not intended to forever limit the scope of AI policy. The purpose is simply to avoid delaying immediately necessary policy-making related to Generative AI.

Scope and Triaging

Primarily focused on Generative AI (GenAI)

Definition of Generative AI: “Generative AI . . . refers to a class of technologies that generate novel outputs such as text, images, audio, code, or video in response to user prompts. These technologies include LLMs, diffusion models, and other neural network architectures designed for content generation. Generative AI is a form of machine learning that creates new content rather than simply analyzing or classifying existing data. These systems are typically trained on vast datasets composed of publicly available digital content—words, images, and sounds . . . . Contemporary models increasingly incorporate curated, domain specific, and proprietary data tailored to specific applications, including educational ones.”

This policy’s focus on GenAI is justified by the uniquely high potential of this particular type of AI to affect the learning environment at FCCPS and the rapid adoption of this technology across society.

This policy will also consider other forms of AI that are immediately relevant to the management of Gen AI, such as AI predictive tools purporting to reliably detect whether student work product relied on GenAI.

Additional Working Definitions

Artificial intelligence (AI) is a label given to a computing system that can perform a task commonly associated with human intelligence. The specific technologies given this label have varied widely over time as computing systems have evolved. What we consider AI today may not be considered AI in the near future.

Language models are computing systems that predict sequences of words in response to an input. Originally designed to use strict grammatical rules, the language models began to use purely statistical methods for predicting words in the 1980s. Once viewed as a form of artificial intelligence, these methods are now considered old forms of machine learning.

Large language models (LLMs) are the name for the current iteration of language models. They are based on a new computational technique, called the transformer model, that allows language models to be run on GPUs. This allows the models to calculate statistics over larger sets of training data than was previously possible. As with any language model, the outputs are sequences of words based on the statistics from their training data.

AI Literacy:  “AI Literacy is the knowledge and skills needed to interact with artificial intelligence (AI) systems effectively. It is not just about understanding how AI functions, but also about being able to use it responsibly, monitor its performance, and think deeply about its role in our lives. This includes asking important questions about how AI is made and used, recognizing both its positive aspects and potential issues, and considering the moral questions it raises.”

Categories of Potential AI Use Considered in this Policy:

Following is an outline of the general use scenarios contemplated in this policy. This is not intended to be a complete inventory of all possible AI use cases warranting policy-making, but it is intended to be a triaging of the most immediately pressing issues for this initial instantiation of the AI use policy.

Use of GenAI by School Staff

To develop instructional materials

To assess students and prepare feedback on their work

To assist in the drafting of day-to-day administrative documents (i.e., not student-facing)

To assist in the drafting of administrative documents with significant ramifications for students’ educational rights (e.g., IEP and 504 plans)

Use of AI by School Staff to Attempt to Detect GenAI

Use of GenAI by Students

To obtain assistance in production-oriented assessments (e.g.,):

Writing essays

Production of visual art

Production of computer code

To obtain assistance in formative assignments

To obtain general tutoring on academic subject matter

To seek counseling on matters typically addressed by human professionals (e.g., mental and physical health, college and career planning)

Use of Specialized GenAI Tools by Teachers and Students:

Grammar and style-checking

Translation

Transcription and Reading Services

Will we cover?

Questionable use of GenAI by students that might have counseling ramifications (e.g., AI companions). How far in loco parentis are we going to go here.

Outright abusive applications of GenAI that affects the school community (e.g., GenAI as a tool for harassment and bullying)
