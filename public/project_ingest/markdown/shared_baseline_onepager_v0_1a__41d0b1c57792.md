<!-- provenance:{"extractor_version":"2.0.0","pipeline_version":"2.0.0","project":"FCCPS AI Committee"} -->

Shared Baseline (Working): AI Definitions, Assumptions, Misconceptions

Rapid-adoption one-pager (non-binding, living baseline) • v0.1a • 20 Feb 2026

Purpose. Lock shared language and “baseline realities” so the committee can move into Values & Principles without re-litigating definitions each meeting.

Baseline assumptions / realities to plan around

- Access is inevitable. Students/staff will have GenAI access regardless of school policy; governance must manage use, not assume prevention.

- Detection is weak. Policy should emphasize process evidence, transparency, educator judgment, and assessment design.

- Benefits are uncertain. Outcomes will vary by context; policy should be evidence-informed and iterative.

- Risks are real. Privacy, integrity, harmful content, and over-reliance require guardrails, training, and monitoring.

High-salience claims and “what we say instead”

Adoption language: Adopt as a non-binding, living shared baseline for the remainder of the committee’s work; revise as evidence and district context evolve.

| Claim | Working corrective framing (policy posture) |
| --- | --- |
| “AI replaces teachers.” | AI may automate tasks; policy should preserve human judgment, relationships, and non-delegable educator responsibilities. |
| “AI hurts learning / makes us dumber.” | Unstructured use can undermine learning; policy should require learning-centered use (scaffolds, reflection, limits on full automation). |
| “AI use is cheating.” | Use depends on intent + transparency; policy should define allowed, conditional, and prohibited uses by task type and grade band. |
| “We can tell when someone used AI.” | Often not reliably; policy should avoid “forensic detection” and focus on authentic assessment + process evidence. |
