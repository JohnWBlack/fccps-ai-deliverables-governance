<!-- provenance:{"extractor_version":"2.0.0","pipeline_version":"2.0.0","project":"FCCPS AI Committee"} -->

Shared Baseline for AI Committee

Due: Tuesday Feb 17 EOD

Miro

# Strategic Issues

## Purpose of AI Policy

The Falls Church City Public Schools (FCCPS) School Board has committed to developing a comprehensive Artificial Intelligence (AI) policy during the 2025-26 school year. This policy will provide guidance on:

how students learn to use AI as a foundational tool for future study and work

how our schools integrate AI into the design and delivery of education to enhance

teaching and support to educators

personalized learning and the overall student experience.

This policy will provide guidance regarding how to capture the benefits that AI may create and how to mitigate the risks and community concerns posed by AI.

## Principles for Developing Policy

As the FCCPS develops its policy, the policy must be developed with the following principles:

Evidence-informed. The policy should clearly articulate the human skills, competencies, and other outcomes it prioritizes. Recommendations should be clearly connected to these outcomes and supported by evidence. The strength of recommendations should be in proportion to the evidence available, as appropriate.

Alignment with IB values. The AI policy should align with the values and learning goals for the IB program, which is designed to build the following five skills:

Thinking (critical, creative, and ethical)

Research (comparing, contrasting, validating and prioritizing information)

Communication (written and oral, effective listening, and formulating arguments)

Social (forming and maintaining positive relationships, and conflict resolution)

Self-management (organizational skills, such as managing time and tasks, and affective skills, such as managing state of mind and motivation)

Age-appropriate. Approaches to learning and risks of AI usage vary by age. The IB program in FCCPS takes different approaches to learning based on age. For example, the Primary Years Programme encourages PK-5 students “to become active, caring, lifelong learners.” As students age, the Middle Years Programme for grades 6-10 encourages students “to become creative, critical and reflective thinkers.” Finally, in high school, the Diploma Programme and Career Programme equip students in grades 11-12 with skills tailored to the pathway they will choose to pursue after graduation.

Centered on the needs of our students and educators. While we must look to research, policy professionals, and other communities for guidance in creating our policy, such guidance may not always be appropriate for or replicable in our community. We must ensure that feedback from our students, parents, and educators are prioritized when assessing whether a new AI-policy action is appropriate or effective.

Evolutionary. This is the school’s first AI policy and AI is evolving rapidly. The policy created by the school system should be revised more frequently than other policies that deal with slower-moving issues. This will require frequent re-assessment of the policy and its implementation.

## Challenges

We have identified the following challenges that make adoption of AI in FCCPS challenging. A successful policy must clearly address these challenges.

The benefits of using AI in K-12 education are highly uncertain. If the benefits of AI in K-12 were clearly supported by school experience or research, the appropriate actions would be clear. In reality, some schools have reported amazing gains from the use of educational technologies and AI, while the broader literature contains many studies showing that AI technologies may undermine learning or fail to improve the lives of its users. Just because one school system managed to implement this new technology well, does not mean that another school system will necessarily achieve a similar result.

The use of AI introduces risks. AI introduces novel risks associated with academic integrity; for instance, by making it easier to cheat on writing assignments. Students may be less likely to reach out to a human for mental health issues. AI makes it easy to create hurtful or otherwise inappropriate images, videos, and sound recordings, including of other students and teachers. There are privacy concerns associated with student information being uploaded to servers the school does not control; student inputs may get used for training purposes, which present a pathway for leaking sensitive information to the broader community. Whether adequate guardrails can be incorporated into AI systems is currently unknown.

Students and educators will have access to AI regardless of school policy. This means that those who choose to adopt the technology may be perceived as having an unfair advantage over those that do not adopt AI; this applies to both students and teachers alike. Likewise, educators may use the technology against the wishes of students and parents who do not want their work run through an AI system.

It is generally not possible to tell when a student or educator has used AI. This makes any rule or policy potentially difficult to enforce.

Teacher preparation. [TBD]

Equity and access. [TBD]

# Current State of AI and Education

## Working definitions

Artificial intelligence (AI) is a label given to a computing system that can perform a task commonly associated with human intelligence. The specific technologies given this label have varied widely over time as computing systems have evolved. What we consider AI today may not be considered AI in the near future.

Language models are computing systems that predict sequences of words in response to an input. Originally designed to use strict grammatical rules, the language models began to use purely statistical methods for predicting words in the 1980s. Once viewed as a form of artificial intelligence, these methods are now considered old forms of machine learning.

Large language models (LLMs) are the name for the current iteration of language models. They are based on a new computational technique, called the transformer model, that allows language models to be run on GPUs. This allows the models to calculate statistics over larger sets of training data than was previously possible. As with any language model, the outputs are sequences of words based on the statistics from their training data.

Generative AI (GenAI) is the label given to LLMs and the broader set of tools that have extended the functionality of LLMs to create statistical predictions of images, audio, video, code, or other forms of output.

AI Literacy:  “AI literacy is a set of foundational skills and competencies that enable individuals to understand how AI works, responsibly evaluate AI systems, and use AI effectively as a human-centered tool across various contexts, including learning, work, and civic applications, while adapting to its ongoing evolution.” (Digital Promise)

AI Education: The study of how to design, build, and research artificial intelligence systems. It involves developing the technical knowledge and skills necessary to create, improve, and advance AI technologies. AI education is typically associated with computer science and related technical fields, and includes areas such as programming, machine learning, data science, and algorithm development.

AI in Education: The integration of artificial intelligence technologies into educational environments to support student learning, instructional design, assessment practices, and institutional operations. This includes both instructional applications—such as personalized learning and generative AI tools—and administrative uses that improve efficiency and decision-making.

## Example Classroom Scenarios

Types of Impacts of AI on Education

“Teaching About AI”. A topic that needs to be integrated into the curriculum (see AI Literacy and AI Education)

“Teaching with AI.” A new kind of Educational Technology to be adopted.

A system-level transformation issue. [Use cases span instruction, planning, and operations. AI can change learning, instruction, and assessment. Brings up issues for academic integrity, data privacy, and equity. Requires Teacher Professional Development]

Usage

Students use tools like ChatGPT widely for school work.

Educator use is highly variable.  Many are using for lesson planning, feedback, and grading.  Some use for identifying at-risk students.

Usage is often done without formal training.

Consent to use AI is not currently sought in FCCPS, nor is disclosure of its use.

Use Cases & Classroom reality

Nice website for tracking use cases: https://www.edtechinsiders.ai/

Many of AI’s strengths in speed, convenience, and emphasis on output are at odds with educational goals of cognitive growth, independent thinking, deep understanding, and social-emotional growth.

A few classroom vignettes:

Personalized Academic Support. A student uses an AI to work through adaptively created algebra problems that reinforce concepts that the student has had trouble with. Through a chat interface, the student is able to ask questions and receive responses regarding the lesson and potential mistakes they have made. The student may see their grades improve, potentially giving them an unfair advantage over other students who do not wish to use AI for ethical reasons.

Writing Assistance. A student uses an AI to generate ideas for an essay, including an outline of the paper. The student drafts the essay with active help from the AI. The teacher is not sure whether this is analogous to receiving peer feedback on their work or whether it has crossed a line into an inappropriate level of writing assistance.

Teacher Productivity Support. A teacher uses AI to design curriculum and daily lesson plans, freeing up their time for other pursuits. The teacher also uses AI to speed up grading of student assignments. The teacher has freed up substantial out-of-class time; however, it is not clear how this translates to an improvement in the quality of time the teacher spends interacting with students during class.

Consent and Transparency. The school installs a genAI chat system on all school-provided devices without seeking parental consent from the parents of the affected children. Teachers use AI to support their productivity, uploading student work to genAI systems without seeking parental consent. For various reasons, teachers do not consistently disclose their use of the genAI.

## Functions of AI and Research Regarding Educational Outcomes

Functions for Students

Functions for Teachers

# Considerations for Policy Design

## Federal, State, and Local Policies

Virginia provides a succinct set of Guidelines for AI Integration that were released as part of a 2024 Executive Order issued by then-Governor Youngkin. These guidelines boil down to: do no harm; don’t replace humans; use AI to empower success; keep updated, include professional development.

In 2025, the State Council of Higher Education for Virginia supported a Summit of experts and leaders to create a comprehensive Reference Guide for AI Integration in Education in the Commonwealth of Virginia. They found that K-12 schools are at a relatively low level of readiness for AI; at this stage, there are significant needs in infrastructure and teacher training. Appropriate actions are early-stage pilots in tutoring and foundational literacy. These pilots should be conservative and on an opt-in basis. They also noted that younger learners require heightened privacy protections and require age-appropriate safeguards.

They also recommend a method for gathering frequent feedback from the local community. Called a Rapid-Alert & Re-Assessment Pathway, this method:

Invites reports from every stakeholder—teachers, administrators, and students—through a one-click online form and a dedicated helpline.

Triage-flags submissions within 48 hours (e.g., data-privacy breach, discriminatory outputs, instructional harm) and posts a public “under review” notice for the tool in question.

Convenes an expert review panel (VITA, VDOE, SCHEV, and classroom practitioners) to decide whether to (a) maintain approval, (b) approve with conditions, or (c) suspend clearance pending vendor remediation.

Closes the loop with the reporter and publishes an outcome summary so that divisions and colleges have a clear, shared understanding of the tool’s status.

Logs all incidents in an open dashboard to spot systemic risks and guide future policy updates.

## Policies From Peer School Systems

Arlington: https://www.apsva.us/digital-learning-innovation/aps-generative-ai-guidance/

Focused on adoption of GenAI. Hits a lot of good topic areas, lacks information about grade bands and any scaling in terms of restrictions on use.

Fairfax (not sure if there is a policy?)

https://ai.fcps.edu/ai-resources

https://go.boarddocs.com/vsba/fairfax/Board.nsf/files/DPXM8R5A0B00/%24file/Academic%20Matters_AI_Jan%208th%202026.pdf

Alexandria City Public Schools: https://www.acps.k12.va.us/departments/technology-services/ai

Montgomery County (Draft for Comment, Ed Tech): https://www.montgomeryschoolsmd.org/siteassets/district/departments/policy-public-comment/igsdraft.pdf; https://issuu.com/mcpsva/docs/mcps_ai_literacy_plan_

## Other Guidance

Strong Resources for Policy Development. Teach AI Policy Resources. TeachAI is led by education and technology experts from reputable organizations. Offers specific toolkit for developing policy. Includes editable documents and slides. Centered around 7 principles: https://www.teachai.org/policy

Purpose: Use AI to help all students achieve educational goals.

Core question: What are the shared educational goals and values - how can AI help achieve them?

Compliance: Reaffirm adherence to existing policies.

FERPA and COPPA compliant?

EdTech policies? Academic Integrity Policies

Knowledge: Promote AI Literacy.

Support staff and students

How is AI literacy integrated in curriculum?

Balance: Realize the benefits of AI and address the risks.

Identify Opportunities, Risks, and Guardrails

Integrity: Advance academic integrity.

Clear policies.  May need rethinking of assignments. Define levels of AI usage (Permissive > Restrictive)

Agency: Maintain human decision-making when using AI.

Humans are ultimately responsible

Evaluation: Regularly assess the impacts of AI.

Identify who is in charge of this.

Grade Bands

Example with Grade Bands:

https://northport.k12.ny.us/ourpages/auto/2025/3/28/65186716/NENUFSD%20K-12%20Artificial%20Intelligence%20%28AI%29%20Use%20Guidelines.pdf

Why should the policy have grade bands?

Use of AI and Learning about AI will vary over the course of development. AI usage should scale with grades.

Younger students should have limited , structured exposure; mostly teacher facing

Older students may have guided AI collaboration or independent use

Suggested Grade Bands: PK, K-2, 3-5,6-8,9-12

Follows FCCPS school structure

Follow grade bands from existing frameworks in AI education [K-2, 3-5, 6-8,9-12]

https://csteachers.org/ai-priorities/

https://ai4k12.org/

# Appendix: Annotated resources

## Guidance on Implementing K-12 AI

What States Get Wrong In Their AI Education Guidance – And How To Fix It (The Learning Agency 2026).

Need list of AI-powered EdTech Tools that are vetted for safety and efficacy

Districts need teacher training and AI tech upgrades

Ongoing support (staff) is needed for implementation

Address AI cheating and plagiarism

Protecting student privacy shouldn’t fall to the just the district

## Role of Parents in AI Policy

https://www.the74million.org/article/schools-need-to-adopt-clear-rules-for-ai-use-parents-can-help-make-that-happen/

## General Resources

https://digitalpromise.org/

https://www.teachai.org/

https://the-learning-agency.com/

https://csteachers.org/ai-priorities/

## AI Literacy Resources

AI Literacy in PK-12 Education (Digital Promise 2025). Contains Skills and Competencies for both Educators and Learners.

AI competency framework for students (UNESCO 2024). Detailed and focuses on students.

AI competency framework for teachers (UNESCO 2024). Detailed and focuses on teachers.

Empowering Learners for the Age of AI: An AI Literacy Framework for Primary and Secondary Education. (OECD and Teach AI 2025).  New Framework: Engaging with AI, Creating with AI, Managing AI, Designing AI.

## Efficacy of AI in Learning Environments

### Kosmyna 2025. “Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task.”

Relevance: Using genAI during initial essay writing appears to be far less effective than using a brain-only or search-engine-enhanced approach for cultivating the IB values of critical thinking, creative thinking, and communication. Using genAI during the ideation stage of a project leads to an echo chamber effect where essay topics cluster around the top responses of the LLM, which themselves may be affected by the business priorities of the LLM company. “These findings support an educational model that delays AI integration until learners have engaged in sufficient self-driven cognitive effort.”

Summary: This Time article provides a plain-language summary. Adults (54) were assigned 4 20-minute essay writing tasks that are based on SAT writing prompts. While writing, their brain activity was measured by EEG. The adults were sorted into three groups; those that could write their essay 1) with the help of only chatgpt, 2) with the help of internet resources but no AI assistance, and 3) without any outside help, similar to the environment of taking the SAT. The research found the group that was allowed to use ChatGPT had the lowest brain engagement and “consistently underperformed at neural, linguistic, and behavioral levels.” In subsequent interviews, this group struggled to recall what they had written, whereas the other groups had retained substantial recall of their work. The essays created by the chatgpt users were more homogeneously written in terms of the concepts used to respond to the prompt and the language used to write the essay. The group that was forced to use only their brains–no outside help–showed the highest neural activity in areas that are associated with creativity, memory, and the ability to process meaning. This paper is not peer-reviewed.

## Efficacy of AI in Work Environments

### Yotzov et al. 2026. “Firm Data on AI.” Working Paper No. 34836. Working Paper Series. National Bureau of Economic Research.

Relevance: If the experience of a school system is analogous to over 80 percent of firms, we should expect that AI will not displace teachers because AI will have a trivial effect on productivity.

Summary: Survey of almost 6000 CFOs, CEOs and executives from firms across the US, UK, Germany and Australia. Around 70% of firms actively use AI. Over 80% of firms report AI had no impact on either employment or productivity. Firms predict sizable impacts over the next 3 years, forecasting AI will boost productivity by 1.4%, increase output by 0.8% and cut employment by 0.7%.

## Unsorted

Office of Educational Technology (archived page bc it’s gone). These are the docs they were sharing.

Empowering Education Leaders: A Toolkit for Safe, Ethical, and Equitable AI Integration (real link is down, here’s a mirror)

Artificial Intelligence and the Future of Teaching and Learning Insights and Recommendations (link)

Designing for Education with Artificial Intelligence: An Essential Guide for Developers (link)

Navigating Artificial Intelligence in Postsecondary Education: Building Capacity for the Road Ahead (link)

This group, Digital Promise, seems to be behind the materials that were created. A very brief impression of their youtube materials seems to indicate that they are leaning very tech forward, very all-in for AI. Not a problem, but keep it in mind as a potential bias in the data / information they present and as an indication of their incentives for recommendations.

Fairfax County Public Schools

AI Resources Landing Page

AI For Education

Has some links to various resources (link)

Four Frictions: How To Resist AI in Education (link)

THIS WAS GOOD. Scrape the important ideas.

Help Sheet: Resisting AI Mania in Schools (ref)

This has tons of links.

| Assumptions | “STUDENTS UNDERSTAND HOW AI WORKS” — Upvotes: 1 dot |
| --- | --- |
| Misconceptions | “AI is a new kind of literacy” |
| Assumptions | “ENHANCING STUDENT LEARNING” — Upvotes: 1 dot |

| Assumptions | “Parents must have a voice…” — Upvotes: none visible |
| --- | --- |

| Assumptions | “We must specify that the policy needs be cyclically revisited” (“ANNUALLY?” written along the side) — Upvotes: none visible |
| --- | --- |
| Assumptions | “Policy can’t be time bound only for review due to velocity of change” — Upvotes: none visible |
| Misconceptions | “This policy is: ABSOLUTE / LITERAL / INFLEXIBLE / FOREVER” |
| Misconceptions | “Gen AI is THE ONLY AI THAT MATTERS” |

| Misconceptions | “AI replaces teachers” — 5 dots |
| --- | --- |
| Misconceptions | “AI HURTS / impedes LEARNING” — 3 dots |
| Misconceptions | “AI will make us DUMBER” — 2 dots |
| Assumptions | “We do not know if AI will produce net benefits” — Upvotes: none visible |
| Misconceptions | “Community members must leverage AI or become irrelevant” — 1 dot |
| Misconceptions | “AI will save time or money” |
| Misconceptions | “AI will make our FCCPS community dumber.” |
| Misconceptions | “AI will REPLACE TEACHERS” |
| Misconceptions | “Misconception: Schools need to be as cutting edge as workplaces” |
| Misconceptions | “Wealthy schools will have unfair advantage with AI” |

| Misconceptions | “Adequate guardrails can be baked into AI software” — 2 dots |
| --- | --- |
| Misconceptions | “It’s JUST GOOGLE” |
| Misconceptions | “AI use is cheating” |
| Student Use | “Constrained — Student + teacher write entire response w/o edits / personal contributions” — Upvotes: 2 dots |
| Student Use | “Constraint: AI generated papers” — Upvotes: 1 dot |

| Assumptions | “Students & staff will have AI access regardless of school policy” — Upvotes: 5 dots |
| --- | --- |

| Misconceptions | “Misconception: YOU know when you are using AI” |
| --- | --- |
| Misconceptions | “We can tell when a student or teacher uses AI” |

| Function: | Brainstorming |
| --- | --- |
| Positive Evidence | - |
| Negative Evidence | Kosmyna 2025. Topics are clustered around the priorities associated with the LLM company. Reduced brain activity associated with creative and critical thinking. Reduced feeling of ownership over final product. |
| Guardrails |  |
| Submissions |  |
| Student Use | “Allowed — Student + teacher research + idea generation” — Upvotes: 1 dot |

| Function: | Writing: First Draft |
| --- | --- |
| Positive Evidence | - |
| Negative Evidence | Kosmyna 2025. Topics are clustered around the priorities associated with the LLM company. Reduced brain activity associated with creative and critical thinking. Reduced feeling of ownership over final product. |
| Guardrails |  |
| Submissions |  |
| Student Use | “Constraint: AI generated papers” — Upvotes: 1 dot |

| Function: | Writing: Summarization |
| --- | --- |
| Positive Evidence |  |
| Negative Evidence |  |
| Guardrails |  |
| Submissions |  |
| Student Use | “Allowed — AI to help synthesize / summarize ideas” (“summarize” appears written over a crossed-out word) — Upvotes: 1 dot |

| Function: | Writing: Synthesis |
| --- | --- |
| Positive Evidence |  |
| Negative Evidence |  |
| Guardrails |  |
| Submissions |  |
| Student Use | “Allowed — AI to help synthesize / summarize ideas” (“summarize” appears written over a crossed-out word) — Upvotes: 1 dot |

| Function: | Writing: Style Coach (includes content suggestions and text formatting) |
| --- | --- |
| Positive Evidence |  |
| Negative Evidence |  |
| Guardrails |  |
| Submissions |  |
| Student Use | “Allowed: AI to identify weaknesses in writing” — Upvotes: 2 dots |

| Function: | Writing: Grammar Coach |
| --- | --- |
| Positive Evidence |  |
| Negative Evidence |  |
| Guardrails |  |
| Submissions |  |
| Student Use | “Student use — Using AI for grammatical review. (changes by band)” — Upvotes: none visible |

| Function: | Personalized / Gamified Learning Apps |
| --- | --- |
| Positive Evidence |  |
| Negative Evidence |  |
| Guardrails |  |
| Submissions |  |
| Student Use | “Allowed: AI driven tool use (Dreambox, Lexia)” — Upvotes: none visible |

| Function: | Media Creation (image, sound, video) |
| --- | --- |
| Positive Evidence |  |
| Negative Evidence |  |
| Guardrails |  |
| Submissions |  |
| Student Use | - |

| Function: | Code Generation |
| --- | --- |
| Positive Evidence |  |
| Negative Evidence |  |
| Guardrails |  |
| Submissions |  |
| Student Use | - |

| Function: | Curriculum design and lesson planning |
| --- | --- |
| Positive Evidence |  |
| Negative Evidence |  |
| Guardrails |  |
| Submissions |  |
| Teacher Use | “Allowed — teachers may use AI to draft lesson ideas, save time on planning” (2 dots) |
| Teacher Use | “TEACHER USE — ALLOWED: AUTOMATED LESSON PLAN GENERATION” (0 dots; note includes a circled “1,” not a dot vote) |
| Teacher Use | “#4 Teacher use ALLOWED — Use AI to flesh out a lesson plan, bringing in fresh examples and designing an interactive, hands-on yet screen-free [activity] for students.” (0 dots) |
| Teacher Use | “Teacher Allowed: The use of AI to aid in curriculum design / scheduling of assignments.” (0 dots) |

| Function: | AI Literacy / Discussion of Risks |
| --- | --- |
| Positive Evidence |  |
| Negative Evidence |  |
| Guardrails |  |
| Submissions |  |
| Teacher Use | “Beneficial: Discussion of risks related to AI use” — Upvotes: 2 dots |

| Function: | Feedback on Student Work |
| --- | --- |
| Positive Evidence |  |
| Negative Evidence |  |
| Guardrails |  |
| Submissions |  |
| Teacher Use | “Teacher CONSTRAINED — The use of AI to suggest/generate feedback on the structure/style of written work.” (1 dot) |
| Teacher Use | “NOT ALLOWED — teachers may not use AI to create grades, feedback without reviewing and approving every word.” (2 dots) |

| Function: | Grading of Student Work |
| --- | --- |
| Positive Evidence |  |
| Negative Evidence |  |
| Guardrails |  |
| Submissions |  |
| Teacher Use | “NOT ALLOWED — teachers may not use AI to create grades, feedback without reviewing and approving every word.” (2 dots) |
| Teacher Use | “TEACHER USE — NOT ALLOWED: AUTONOMOUS GRADING” (0 dots) |
