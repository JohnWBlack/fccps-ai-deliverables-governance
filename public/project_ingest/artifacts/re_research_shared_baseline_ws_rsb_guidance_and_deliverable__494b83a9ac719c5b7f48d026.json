{
  "artifact_id": "494b83a9ac719c5b7f48d026",
  "doc_type": "txt",
  "extracted_at_utc": "2026-03-01T04:41:17.369910Z",
  "file_mtime_utc": "2026-02-27T19:47:55.370315Z",
  "provenance": {
    "extractor_version": "2.0.0",
    "pipeline_version": "2.0.0",
    "project": "FCCPS AI Committee"
  },
  "sections": [
    {
      "heading_path": [],
      "section_id": "sec_0001",
      "text": "From:\tTom Colvin <[redacted-email]>\nSent:\tThursday, 19 February, 2026 20:18\nTo:\tJohn Black\nSubject:\tRe: Research & Shared Baseline (WS-RSB): guidance and deliverable for 20 Feb\nAttachments:\tShared Baseline v01.docx; Shared Baseline v01.pdf\n\nImportance:\tHigh\n\nCategories:\tFCCPS AI Advisory Committee\n\nHey John,\n\nI'm not sure how close this comes to answering the mail. In the time available, we were \nmore able to gather resources than to read them.\n\nWe directly answered the mail on key terms and classroom examples. We have a large list \nof resources, however getting them annotated is going to be a work in progress. Some of \nthem, we wrote the relevant summaries in the main text; however, most of them are in an \nappendix at the moment."
    },
    {
      "heading_path": [],
      "section_id": "sec_0002",
      "text": "As we discussed over email, the assumptions, misconceptions, and a few of the \nstudent/teacher use cases were distributed into Purpose (what we're trying to do), \nPrinciples (how we will try to do it), and Challenges (what makes creating a good policy \nhard). The positive framing for the misconceptions are that they are real risks / challenges \nthat the policy has to grapple with. Likewise, the concept of misconceptions and what's \nreliable / brittle have been started in the evidence-table format. I stand by that it is \npremature / oversimplified to say that any of these things are good / bad / reliable / brittle \nwithout being able to point to evidence. My opinions on them, and the opinions of the \nbroader group, should not be a sufficient basis for assessing what are essentially empirical \nclaims. So my hope is that in the discussion tomorrow, I can ask folks to take a look on \ntheir own time, suggest potential functions of AI that should be added to the list and to \nprovide any research / evidence they are aware of to act as positives or negatives for the AI \nfunction getting used in K-12 education. Elizabeth and I can keep updating the list as the \nweeks roll on."
    },
    {
      "heading_path": [],
      "section_id": "sec_0003",
      "text": "Attaching the living document as it stands now as docx and pdf. This is ultimately hosted \non google drive, so we could also give people a read-only link since i think that's easier to \ndigest than Miro, which i admit I have a hard time following. Miro and similar infinite-\nwhiteboard services are challenging for me navigate, but maybe that's just me. Anyways, if \nit's not a violation of any policy and you think it would be helpful, i can share a read-only \nlink, let me know.\n\nCheers and see you tomorrow!\nTom\n\nOn Mon, Feb 16, 2026 at 10:39?PM John Black <[redacted-email]> wrote:\nHi Tom.\n\nThank you. Your pushback here is exactly the right kind (and I don’t want you to feel like \nyou need to “spin” anything).\n\nA few quick clarifications to de-stress this:\n\n*\t“Misconceptions” = high-salience claims/concerns we must address, not \nthings we can definitively debunk. For items like “AI replaces teachers / hurts \nlearning / makes us dumber,” it’s totally OK to frame them as real risks. The \n“corrective framing” can simply be: what part may be true, under what conditions, \nand what guardrails / policy posture we use to manage it."
    },
    {
      "heading_path": [],
      "section_id": "sec_0004",
      "text": "*\tOn “reliable vs brittle”: I’m not asking for “AI is always correct.” I mean lower-risk \npatterns when paired with guardrails (e.g., low stakes, human verification, \nprocess evidence, no sensitive data). It’s fine—even helpful—to call out where \nsomething looks reliable but can fail badly or harm learning outcomes.\n\n*\tYour evidence-table idea is perfect for Meeting 3. A “function ? potential upside \n? potential downside ? evidence (strong/mixed/limited) ? guardrails” table is an \nexcellent way to keep this evidence-informed without overclaiming. If you can get \neven 3–5 rows to v1, that’s plenty—we can iterate.\n\nNet: bring what you and Elizabeth have by Friday; partial is fine. Our goal on 2/20 is to \nreduce uncertainty enough to converge on values/principles, not to eliminate uncertainty \nentirely.\n\nBest, \nJohn\n\nFrom: Tom Colvin <[redacted-email]>  \nSent: Monday, 16 February, 2026 22:05 \nTo: John Black <[redacted-email]> \nSubject: Re: Research & Shared Baseline (WS-RSB): guidance and deliverable for 20 Feb\n\nThanks for the swift response! My response.\n\nOn Mon, Feb 16, 2026 at 8:21?PM John Black <[redacted-email]> wrote:\nHi Tom,"
    },
    {
      "heading_path": [],
      "section_id": "sec_0005",
      "text": "Thanks for the update — and for meeting with Elizabeth over the weekend to push this \nforward. It sounds like you’re in a good place. A few clarifications on each of the \nquestions you raised:"
    },
    {
      "heading_path": [],
      "section_id": "sec_0006",
      "text": "1) Stickies: “assumptions” vs. “misconceptions”\nYou’re right that “misconception” can imply “provably wrong,” which isn’t always the \ncase. Please feel free to treat these as common beliefs/claims we’re likely to hear \n(some wrong, some oversimplified, some genuinely contested) that we should address \nexplicitly in policy + comms/PD. If something can’t be definitively proven wrong, that’s \nstill useful — it becomes part of our shared baseline of “what people think / what needs \nclarification.”\nYour refactor into purpose / principles / challenges makes total sense and is helpful. \nThe only additional ask for Meeting 3 is: can you still surface a ranked list of Tier 1 items \n(e.g., ~5) with a one-sentence “what we should say instead” framing for each, plus a \nshort Tier 2 list? That ranked list will be especially useful as we converge on \nvalues/principles.\nI have a hard time seeing how to come up with a pithy reframing that is truthful. For \nexample, three of the 'misconceptions' were\n“AI \nrepl\nace\ns \nteac\nhers\n” — \n5 \ndots\n“AI \nHU\nRT\nS / \nimp\nede\ns \nLEA\nRNI\nNG” \n— 3 \ndots\n“AI \nwill \nmak\ne us \nDU\nMB\nER” \n— 2 \ndots\nEach of those may indeed be true and we can find evidence for them in"
    },
    {
      "heading_path": [],
      "section_id": "sec_0007",
      "text": "the literature. The \nonly real way to reframe them is simply to make them less absolute. \"AI might replace \nteachers. AI can impede learning. AI can make us dumber.\" Whether these things become \ntrue or not in FCCPS depends on the way AI is integrated into the school. It is premature to \nsay that these are wrong or to try to create a more benign framing of these things. The way \nto reframe them are as challenges that the policy and implementation must attempt to \naddress."
    },
    {
      "heading_path": [],
      "section_id": "sec_0008",
      "text": "2) “AI capabilities and limits” --what I meant\nAgreed: a list of modalities (text/image/audio/etc.) isn’t the most helpful output here. \nWhat I’m looking for is plain-language, K-12-relevant guidance on what’s reliable vs. \nbrittle and why it matters for schools.\nExamples of the style that would be most useful:\n*\t“Reliable-ish” use cases (when paired with human judgment): drafting/revising \ntext, brainstorming, generating examples, summarizing with a source in hand, \nfirst-pass differentiation, practice questions, etc.\n*\tCommon failure modes / brittleness: confidently wrong outputs \n(“hallucinations”), weak citations, prompt sensitivity, bias/stereotypes, uneven \nreasoning, math/logic errors, and rapid model/version change.\n*\tPolicy-relevant realities: privacy/records concerns; variability in output; and the \nfact that “detection” is not a dependable integrity strategy.\nIf you can pair each point with a quick “so what for policy/guidance” implication, that’s \nperfect.\nFrom what perspective are you conceiving of reliability? An AI can reliably help a student \ngenerate ideas for an essay (brainstorming), but the research appears to show that is bad \nfor learning outcomes. So for brai"
    },
    {
      "heading_path": [],
      "section_id": "sec_0009",
      "text": "nstorming, did you mean that an AI can reliably do the \ntask (yes) or that it's reliably good for students (no)? Another related issue is that it really \nmatters which AI you're using; math errors are effectively non-existent for an agent that \ncan call tools, but are rampant in agents that don't use tools. That's a clear example, but it \napplies to pretty much everything; depending on the model you're using and the context \nit's been fed, all of the reliable-ish use cases you listed can fail miserably. I've had it revise \nmy text in ways that fundamentally change meaning to make the output wrong. I've had \nthem brainstorm ideas for me that were nonsense and provide examples of things that \nweren't true; a non-expert would probably have thought they were fine, but it's clear to me \nthat they're deeply wrong. They can summarize sources when fed a document, but will \noften miss the important nuances that made the paper interesting. Etc."
    },
    {
      "heading_path": [],
      "section_id": "sec_0010",
      "text": "I'm also not sure why we would list all the things an AI can \"reliably\" do unless we're \nimplicitly suggesting that they're good for use in schools; e.g., we wouldn't say things like \n\"AI can reliably make deepfakes of people you know\" because that's not a thing we would \nwant to highlight as a use case in school. However, we can't say any of the things on this \nlist are good for use in schools until we find some research that says one way or the other. \nSo it seems like such a list risks being just vibes and not reflective of the evidence-\ninformed approach that Bethany said would be used to create the policy.\n\nAs you can see, I'm not sure how to respond to this task. How are you planning to use this \ninformation? If I understand where this type of information is going, then maybe I can \nbetter see how to create it."
    },
    {
      "heading_path": [],
      "section_id": "sec_0011",
      "text": "3) “Classroom reality” -- FCCPS vs. general vs. hypothetical\nPlease use hypothetical but plausible vignettes — they do not have to be validated as \n“this is exactly what FCCPS students are doing today.” The goal is to make the baseline \nconcrete and shared, so we can draft principles and guardrails against real-looking \nsituations.\n3–5 short scenarios across:\n1.\tstudent use for learning,\n2.\tteacher use (instructional + professional), and\n3.\tassessment integrity “triage” (what’s allowed/expected vs. not).\nIf you can add a sentence on what changes by grade band (PK–2 / 3–5 / 6–8 / 9–12), even \nlightly, that will tee up the grade-band discussion.\nOkay. So it sounds like a vignette that reflects how Alpha School has incorporated AI is not \nwhat you're after; they claim to have amazing results but they also have replaced \n\"teachers\" with a new role called \"guides\" that is basically there to keep the kids \nmotivated to continue using the app where they learn. SAT scores are off the charts, but \nthey no longer have a teacher-at-front-of-classroom model. I'm also keying in on your \n\"guardrails\" comment; I went to a falls church parents meeting on AI in schools a few \nweeks ago and heard so"
    },
    {
      "heading_path": [],
      "section_id": "sec_0012",
      "text": "me things that I know they are unhappy about, so I can work that \nin there."
    },
    {
      "heading_path": [],
      "section_id": "sec_0013",
      "text": "4) Your outline / scope\nThe outline you shared looks good. The only guidance I’d add is: for this checkpoint, \nplease don’t feel pressure to fully build out longer sections (e.g., policy scan, broader \nresearch landscape, IB skills mapping) unless they’re already easy to include. If you have \nthem, great -- but it’s also fine to keep those as brief bullets or an appendix and focus \nyour “front page” effort on the definition-of-done items.\nCool. I imagine this is a document that Elizabeth and I will continue to build as we find \nmore research and connect the findings to the outcomes that folks are hoping to create.\n\n5) Timing / stress level\nPlease don’t treat Tuesday EOD as a hard deadline. If you can send a “good enough for \npre-reads” snapshot by Tue 17 Feb (even if some parts are bullets), I’ll use it. If that’s \nstressful, it’s completely fine to finish what you plan to present by Friday. The goal is \nclarity and usefulness, not perfection."
    },
    {
      "heading_path": [],
      "section_id": "sec_0014",
      "text": "6) What to plan for on Friday (Meeting 3)\nLet’s plan for ~8–10 minutes for you and Elizabeth to walk the committee through:\n*\ttop 5–7 baseline takeaways (capabilities/limits),\n*\tTier 1 misconceptions/beliefs list + corrective framing,\nNeed more guidance on these two if it's what you really want because, as i said before, it's \nnot that clear cut. I'll think about it ... maybe i'm just getting hung up on the idea of \n'reliable'. I can see maybe a table like"
    },
    {
      "heading_path": [],
      "section_id": "sec_0015",
      "text": "This is what i was hoping to do anyways with the IB values. It's easier to do it with the IB \nvalues because there are simply fewer of them than possible use cases to articulate. \nRegardless, we could start this list and then have folks who know of certain research that \nthey want to be captured send it to me and I'll populate the table. I plan to continue \ncombing for studies as this subcommittee goes on so that we can know what the research \nsays on as much as possible.\n*\t \n*\t3 scenarios + grade-band notes, and\n*\tany “open questions” you want the committee to keep in mind as we pivot into \nValues/Principles.\nWe’ll do a quick Q&A, and then we’ll use your outputs directly as inputs for the Values & \nPrinciples convergence work.\nThanks again--This baseline is a key dependency for the rest of the workstreams, and \nwhat you’re describing is exactly what we need.\n\nBest, \nJohn Black\n\nFrom: Tom Colvin <[redacted-email]>  \nSent: Monday, 16 February, 2026 18:40 \nTo: John Black <[redacted-email]> \nSubject: Re: Research & Shared Baseline (WS-RSB): guidance and deliverable for 20 Feb\n\nHey John,"
    },
    {
      "heading_path": [],
      "section_id": "sec_0016",
      "text": "Elizabeth and I met up over the weekend and have been working on this. We have a few \nquestions and comments before we finish up.\n\nStickies about Assumptions and Misconceptions. We think we know what you were \ntrying to get at with these. Calling them 'misconceptions' implies that we can prove that \nthey are wrong. Since we can't prove that, they are just more assumptions. Further, these \nassumptions / misconceptions were really pointing to either the intended purpose of the \nstrategy, the principles by which the strategy should be created, and the challenges \nassociated with creating a strategy that meets the purpose and principles. So we've \nrefactored the sticky responses into those three categories and supplemented them with \ninfo from the FCCPS school board website.\n\nAI capabilities and limits. Not sure what you meant by this. A list of high level stuff like \ntext completion, code completion, image generation, sound generation, move \ngeneration doesn't seem helpful. Not sure if you wanted to know what the companies \nthat sell AI-enhanced ed-tech are hawking to get a list of capabilities tailored to K-12? \nMaybe, but then ..."
    },
    {
      "heading_path": [],
      "section_id": "sec_0017",
      "text": "Classroom reality. Presumably this is where the K-12 specific stuff would go? Is this \nsupposed to be how students are using now in FCCPS, anywhere in the world, or \nhypothetical vignettes that illustrate the opportunities and challenges of AI in the \nclassroom?\n\nHere's the outline as it stands now, though it will be difficult to get it all filled out by EOD \ntomorrow. Can we send something like where we're at tomorrow but then have a few \nmore days to finish up?\n\nOn Friday, I assume we'll get some amount of time to talk about what we did and what \nwe found. What should we plan for?\n\nThanks!\nTom\n\nOn Mon, Feb 9, 2026 at 8:01?AM Tom Colvin <[redacted-email]> wrote:\nRoger that!"
    },
    {
      "heading_path": [],
      "section_id": "sec_0018",
      "text": "On Sun, Feb 8, 2026 at 1:19?AM John Black <[redacted-email]> wrote:\nHi Tom,\nThank you again for leading Research & Shared Baseline, with Elizabeth as co-lead.\nYour next deliverable \nShared Baseline Brief v1 (2–3 pages) for committee review at Meeting 3 (Fri 20 Feb)\nDefinition of done:\n*\tAI capabilities/limits (plain language; practical implications for schools)\n*\tMisconceptions to “kill” (prioritized, with brief corrective framing)\n*\tKey terms / definitions (working definitions suitable for policy drafting)\n*\t“Classroom reality” examples (student use, teacher use, integrity triage)\n*\tAnnotated resource list (top ~10)\nInputs available\n*\tFocus Block sticky-note extractions and dot-votes are on the Miro Shared \nBaseline frame.\n*\tYou can also draw from the Team Formation materials, Resources area, and \nyour own research.\nHow we’ll use this on 20 Feb\n*\tThe Shared Baseline will feed our Values & Principles convergence (8–12 \nprinciples + one tradeoff statement).\n*\tWe are aiming for enough convergence by Meeting 4 (6 Mar) that all \nworkstreams can draft in alignment.\nLogistics\n*\tPlease coordinate directly with Elizabeth on division of labor and synthesis.\n*\tIf possible, please post (or em"
    },
    {
      "heading_path": [],
      "section_id": "sec_0019",
      "text": "ail) v1 by Tue 17 Feb EOD so I can compile pre-\nreads.\nSuggested structure (if helpful)\n1.\tCapabilities/limits (what’s reliable vs brittle)\n2.\tMisconceptions (ranked, with correction)\n3.\tWorking definitions (short)\n4.\tClassroom reality: 3–5 concrete vignettes\n5.\tImplications (what this means for policy design)\n6.\tAnnotated resources (top 10)\nThanks again, \nJohn"
    },
    {
      "heading_path": [],
      "section_id": "sec_0020",
      "text": "John Black | [redacted-phone] | [redacted-email]"
    }
  ],
  "source_hash_sha256": "c4f368b5f54a5a7f1f50843f5171caa5ae2824c9e79f8d5495838788f13bd647",
  "source_rel_path": "workstreams/rsb/Re Research  Shared Baseline (WS-RSB) guidance and deliverable for 20 Feb.txt",
  "title": "Re Research  Shared Baseline (WS RSB) guidance and deliverable for 20 Feb"
}
