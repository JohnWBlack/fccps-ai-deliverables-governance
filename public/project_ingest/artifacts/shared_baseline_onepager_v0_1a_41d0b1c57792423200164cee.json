{
  "artifact_id": "41d0b1c57792423200164cee",
  "doc_type": "docx",
  "extracted_at_utc": "2026-03-01T04:41:17.369910Z",
  "file_mtime_utc": "2026-02-24T21:05:01.009470Z",
  "provenance": {
    "extractor_version": "2.0.0",
    "pipeline_version": "2.0.0",
    "project": "FCCPS AI Committee"
  },
  "sections": [
    {
      "heading_path": [],
      "section_id": "sec_0001",
      "text": "Shared Baseline (Working): AI Definitions, Assumptions, Misconceptions"
    },
    {
      "heading_path": [],
      "section_id": "sec_0002",
      "text": "Rapid-adoption one-pager (non-binding, living baseline) • v0.1a • 20 Feb 2026"
    },
    {
      "heading_path": [],
      "section_id": "sec_0003",
      "text": "Purpose. Lock shared language and “baseline realities” so the committee can move into Values & Principles without re-litigating definitions each meeting."
    },
    {
      "heading_path": [],
      "section_id": "sec_0004",
      "text": "Baseline assumptions / realities to plan around"
    },
    {
      "heading_path": [],
      "section_id": "sec_0005",
      "text": "Access is inevitable. Students/staff will have GenAI access regardless of school policy; governance must manage use, not assume prevention."
    },
    {
      "heading_path": [],
      "section_id": "sec_0006",
      "text": "Detection is weak. Policy should emphasize process evidence, transparency, educator judgment, and assessment design."
    },
    {
      "heading_path": [],
      "section_id": "sec_0007",
      "text": "Benefits are uncertain. Outcomes will vary by context; policy should be evidence-informed and iterative."
    },
    {
      "heading_path": [],
      "section_id": "sec_0008",
      "text": "Risks are real. Privacy, integrity, harmful content, and over-reliance require guardrails, training, and monitoring."
    },
    {
      "heading_path": [],
      "section_id": "sec_0009",
      "text": "High-salience claims and “what we say instead”"
    },
    {
      "heading_path": [],
      "section_id": "sec_0010",
      "text": "Adoption language: Adopt as a non-binding, living shared baseline for the remainder of the committee’s work; revise as evidence and district context evolve."
    },
    {
      "heading_path": [],
      "section_id": "sec_0011",
      "text": "| Claim | Working corrective framing (policy posture) |\n| “AI replaces teachers.” | AI may automate tasks; policy should preserve human judgment, relationships, and non-delegable educator responsibilities. |\n| “AI hurts learning / makes us dumber.” | Unstructured use can undermine learning; policy should require learning-centered use (scaffolds, reflection, limits on full automation). |\n| “AI use is cheating.” | Use depends on intent + transparency; policy should define allowed, conditional, and prohibited uses by task type and grade band. |\n| “We can tell when someone used AI.” | Often not reliably; policy should avoid “forensic detection” and focus on authentic assessment + process evidence. |"
    }
  ],
  "source_hash_sha256": "f2ce710951e9239f5af54b227839f0f1727407716cb0ca1b3437758275bfc749",
  "source_rel_path": "Meetings/03 - Meeting 20-FEB-26/Shared_Baseline_OnePager_v0.1a.docx",
  "title": "Shared Baseline OnePager v0.1a"
}
