{
  "artifact_id": "a8a4f5ce97bb1eef6e9539c7",
  "doc_type": "md",
  "extracted_at_utc": "2026-03-01T17:05:25.474380Z",
  "file_mtime_utc": "2026-01-23T03:22:58.331949Z",
  "provenance": {
    "extractor_version": "2.0.0",
    "pipeline_version": "2.0.0",
    "project": "FCCPS AI Committee"
  },
  "sections": [
    {
      "heading_path": [],
      "section_id": "sec_0001",
      "text": "Approach to Policy Development\n\n**Short answer:** Start with a shared, practical baseline (what AI *is* and *isn’t*), surface diverse values through structured activities, and use small, lowrisk pilots and clear safeguards so committee members can see benefits and limits in context. **Do this before drafting policy.**"
    },
    {
      "heading_path": [
        "Key considerations and decision points"
      ],
      "section_id": "sec_0002",
      "text": "-   **Clarify scope:** Are we regulating tools, classroom practices, or procurement?\n-   **Set success criteria:** What outcomes (equity, learning gains, teacher workload reduction, integrity) matter most?\n-   **Decide pilots:** Which grades, subjects, or tasks will trial human–AI teaming first?"
    },
    {
      "heading_path": [
        "Short workshop plan to level set (3 sessions)"
      ],
      "section_id": "sec_0003",
      "text": "1.  **Session 1 — Shared baseline (60 min):** Quick primer on AI capabilities/limits, examples in classrooms, and common misconceptions; Q&A. **Goal:** common language and dispel “glorified search” myths. 12\n2.  **Session 2 — Values mapping (90 min):** Small groups map priorities to the cognitive pipeline (Create, Compete, Control, Collaborate). Each group lists benefits, harms, and tradeoffs. **Goal:** surface diverse perspectives and tensions. 3\n3.  **Session 3 — Rapid pilots & governance (90 min):** Review 2–3 lowrisk pilot proposals, define humanintheloop checkpoints, data/privacy rules, and evaluation metrics. **Goal:** concrete next steps."
    },
    {
      "heading_path": [
        "Stakeholder engagement tactics"
      ],
      "section_id": "sec_0004.1",
      "text": "-   **Invite diverse voices:** teachers (varied subjects), students, parents, tech staff, curriculum leads, equity officers, and legal/privacy counsel. **Include at least one skeptical teacher** to surface real concerns. 1\n-   **Use artifacts, not abstractions:** show short demo workflows (teachermediated AI feedback on drafts) rather than abstract claims. 2\n-   **Run roleplay scenarios:** “AI suggests a student essay rewrite” — have groups decide actions and document rationale.\n\n**Table: Approaches to open minds (tradeoffs)**\n\n![Embedded widget](media/325472601571f31e1bf00674c368d335.gif)"
    },
    {
      "heading_path": [
        "Stakeholder engagement tactics"
      ],
      "section_id": "sec_0005.2",
      "text": "| Approach                  | Strength                    | Risk                              | How to mitigate                                        |\n|---------------------------|-----------------------------|-----------------------------------|--------------------------------------------------------|\n| Demos + pilots            | Concrete evidence of value  | Overgeneralization from one pilot | Multiple pilots across subjects; clear metrics         |\n| Values mapping workshops  | Surface tradeoffs and buyin | Timeintensive                     | Short, focused sessions with prework                   |\n| Student panels            | Center learner voice        | May be dismissed                  | Summarize and present student recommendations to board |\n| Data & evidence briefings | Credibility for skeptics    | Technical overload                | Onepage briefs + visual summaries                      |"
    },
    {
      "heading_path": [
        "Metrics, safeguards, and governance"
      ],
      "section_id": "sec_0006",
      "text": "-   **Stagespecific KPIs:** engagement for *Create*, calibration/error rates for *Metacognition*, academic integrity incidents for *Compete*, and collaboration quality for *Collaborate*.\n-   **Safeguards:** teacher final approval, disclosure of AI use, parental consent for data, anonymization for model training, and routine bias audits. 12"
    },
    {
      "heading_path": [
        "Quick sample charter language (one line)"
      ],
      "section_id": "sec_0007",
      "text": "*“The committee will prioritize equitable learning outcomes, teacher agency, student privacy, and transparent humanintheloop controls; pilots must include measurable learning and equity metrics before scale.”*"
    },
    {
      "heading_path": [
        "Final recommendation"
      ],
      "section_id": "sec_0008",
      "text": "Start with **one short pilot** (e.g., AIassisted formative feedback in one grade), run it for a semester with teacher oversight, collect evidence, and use that evidence plus structured values workshops to draft policy. This turns abstract fears into concrete tradeoffs and shared decisions."
    },
    {
      "heading_path": [
        "References"
      ],
      "section_id": "sec_0009",
      "text": "1*Guidance for Developing Policies to Govern the Adoption and Use of ...*. <https://files.eric.ed.gov/fulltext/ED655341.pdf>\n\n2*Putting K–12 AI Policies Into Practice \\| EdTech Magazine*. <https://edtechmagazine.com/k12/article/2025/07/putting-k-12-ai-policies-practice>\n\n3*2024_AI Guidance Document - ExcelinEd*. <https://excelined.org/wp-content/uploads/2024/08/2024_AI-Guidance-Document.pdf>"
    }
  ],
  "source_hash_sha256": "c99c61832361477622f5c57cb1e0719866f4651feb84feb22e0b505763228078",
  "source_rel_path": "Members' Corners/John Black/006_Approach-to-Policy-Development.md",
  "title": "Key considerations and decision points"
}
