# Jillian's Corner --- AIEIP Excerpts (Reformatted for FCCPS WS-DPS)

> Source: Jillian Burkley --- excerpts from prior work (doctoral
> capstone / AIEIP), as posted in "Jillian's Corner" on the Miro board.

------------------------------------------------------------------------

## Executive Summary (Excerpt)

**Ethical considerations:** According to CIDDL (2024), ensuring
equitable access to AI technologies is crucial to prevent exacerbating
existing educational inequalities, as students in well-funded schools
may have greater access to cutting-edge AI tools.

These challenges are particularly acute for the 7.5 million students
receiving special education services nationwide (National Center for
Education Statistics \[NCES\] (2024). Without structured intervention,
the increasing adoption of AI tools risks exacerbating educational
disparities rather than reducing them (Holmes et al., 2022).

------------------------------------------------------------------------

## Problem Statement and Evidence of Need (Excerpts)

### Problem statement

The increasing use of AI in SPED presents significant ethical, legal,
and educational challenges. Despite the growing adoption of AI tools in
K-12 education, no standardized federal or state regulations
specifically address the ethical risks and compliance concerns
associated with AI implementation in SPED (DOE, 2023; Roschelle et al.,
2024). This regulatory gap affects approximately 7.5 million students
receiving special education services nationwide (National Center for
Education Statistics \[NCES\], 2024).

AI tools deployed in SPED settings present numerous ethical concerns,
including algorithmic bias, data privacy vulnerabilities, and the risk
of over-reliance on AI-generated recommendations (Haque & Li, 2024).
Current AI tools have been reported to disproportionately misclassify
students from marginalized racial and socioeconomic backgrounds, leading
to inequitable educational interventions (Nguyen et al., 2023).
Additionally, AI systems often function as opaque "black boxes," making
it difficult for educators and parents to understand how decisions
regarding student learning accommodations are made (Maslej et al.,
2023). These concerns raise significant legal questions about the
compliance of AI-driven SPED interventions with IDEA, Section 504, and
FERPA, which mandate that students with disabilities receive fair and
appropriate educational support (Holler & Zirkel, 2008).

### Regulatory and ethical gaps

Current AI-driven educational tools are being rapidly deployed without
adequate ethical oversight or legal frameworks. While federal laws such
as IDEA, Section 504, and FERPA offer essential protections for students
with disabilities, they were not designed to address the unique
challenges posed by algorithmic decision-making (Haque & Li, 2024).

The White House's AI Bill of Rights (2023) emphasizes five key
principles for AI use, including algorithmic discrimination protections
and data privacy, but it is not legally binding and does not provide
specific guidance for educational settings (Maslej et al., 2023).
Furthermore, the U.S. Department of Education has released broad AI
guidelines, but these are not yet integrated into SPED compliance
frameworks (DOE, 2023; Roschelle et al., 2024).

### Additional risk evidence and implementation gaps

These alarming findings highlight the urgent need for structured ethical
frameworks to guide AI implementation in special education settings.

**Data privacy vulnerabilities:** SPED students' sensitive diagnostic
information, behavioral data, and learning accommodations are
increasingly processed through AI systems that lack adequate safeguards
against privacy breaches (Roschelle et al., 2024).

**Lack of professional preparation:** The CIDDL (2024) highlights that
few educators and educational leaders understand AI sufficiently to
effectively advance education and special education. Faculty members
responsible for preparing future special educators often lack access to
comprehensive AI-focused training programs, which inhibits their ability
to effectively integrate AI tools and content into teacher preparation
(CIDDL, 2024). Holmes et al. (2022) highlight significant concerns
regarding data privacy and compliance in AI educational systems, noting
that "no framework has been worked out, no guidelines have been agreed,
no policies have been developed, and no regulations have been enacted to
address the specific ethical issues raised by the use of AI in
education" (p. 505).

**Local Implementation Challenges:** Many school districts lack
governance structures to evaluate AI tools, leading to inconsistent or
unsafe adoption (McMahon & Firestone, 2024). Without clear review
criteria, districts may inadvertently implement AI systems that violate
student privacy or exacerbate inequities in educational support (Nguyen
et al., 2023).

The AI Equity Implementation Program (AIEIP) is designed to address
these challenges by developing ethical guidelines, compliance
frameworks, and professional development structures that ensure
responsible AI use in SPED services.

------------------------------------------------------------------------

## Program Frameworks and Theoretical Foundation (Excerpt)

The AIEIP is grounded in the Diversity, Equity, Intersectionality,
Power, and Anti-Racism (DEIPAR) framework (Dyer & Gushwa, 2023),
ensuring that social justice and inclusion remain central to all
implementation efforts.

**Diffusion of Innovations Theory** (Dearing & Cox, 2018): Guides phased
implementation and adoption strategies.

**Constructivist Learning Theory** (Fernando & Marikar, 2017): Informs
development of training materials engaging educators in experiential
learning about AI ethics.

Together, these frameworks address both technical and social dimensions
of ethical AI implementation in SPED settings.

------------------------------------------------------------------------

## Program Components and Implementation Strategy (Excerpt)

-   **Ethical AI Professional Development**
-   **AI Compliance and Governance Framework**
-   **Bias Auditing and Monitoring**
-   **Stakeholder Engagement and AI Literacy Resources**

This structured approach ensures responsible AI implementation with
continuous oversight.

------------------------------------------------------------------------

## Mission, Vision, and Core Values (Excerpt)

**Core Values:**

-   **Equity**
-   **Transparency**
-   **Accountability**
-   **Innovation**

------------------------------------------------------------------------

## Program Services and Operational Supports (Excerpt)

-   Ethical AI Training Modules\
-   AI Compliance Frameworks\
-   AI Bias Audits and Monitoring\
-   Student and Parent AI Literacy Resources\
-   Professional Learning Communities (PLCs) for AI Ethics\
-   AI Support Groups & Resource Hub\
-   Micro-Credentialing & Certification

**Why AIEIP Is Essential**

-   Data Privacy & Consent\
-   Stakeholder Understanding\
-   Human Oversight\
-   Equitable Access

------------------------------------------------------------------------

## Case Studies (Excerpt)

### Mathematics Education in Greece

-   Personalized worksheets with ChatGPT\
-   Tailored supports aligned with curriculum\
-   Improved test performance and engagement\
-   Ethical consideration: algorithmic bias

(Rizos et al., 2024)

### Active Reading Systems in Japan

-   Learning Evidence Analysis Framework (LEAF)\
-   Real-time analytics and behavior monitoring\
-   Improved early intervention and stakeholder insight\
-   Ethical consideration: data privacy and consent

(Toyokawa et al., 2023)
